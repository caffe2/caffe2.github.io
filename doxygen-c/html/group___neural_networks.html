<!-- HTML header for doxygen 1.8.14-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Caffe2 - C++ API: NeuralNetworks</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="icon" href="/static/favicon.png" type="image/x-icon">
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="stylesheet.css" rel="stylesheet" type="text/css" />
<link href="main.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo" width="56"><a href="/"><img alt="Logo" src="Caffe2-with-name-55-tall.png"/></a></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Caffe2 - C++ API
   </div>
   <div id="projectbrief">A deep learning, cross platform ML framework</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li class="current"><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="annotated.html"><span>Data&#160;Structures</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li><a href="/doxygen-c/html/classes.html"><span>C++&#160;API</span></a></li>
      <li><a href="/doxygen-python/html/annotated.html"><span>Python&#160;API</span></a></li>
      <li><a href="https://github.com/pytorch/pytorch"><span>GitHub</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#files">Files</a> &#124;
<a href="#nested-classes">Data Structures</a> &#124;
<a href="#typedef-members">Typedefs</a> &#124;
<a href="#enum-members">Enumerations</a> &#124;
<a href="#enumval-members">Enumerator</a> &#124;
<a href="#func-members">Functions</a> &#124;
<a href="#var-members">Variables</a>  </div>
  <div class="headertitle">
<div class="title">NeuralNetworks</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="files"></a>
Files</h2></td></tr>
<tr class="memitem:_neural_networks_8h"><td class="memItemLeft" align="right" valign="top">file &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="_neural_networks_8h.html">NeuralNetworks.h</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Data Structures</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="struct_a_neural_networks_operand_type.html">ANeuralNetworksOperandType</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="struct_a_neural_networks_operand_type.html" title="ANeuralNetworksOperandType describes the type of an operand. ">ANeuralNetworksOperandType</a> describes the type of an operand.  <a href="struct_a_neural_networks_operand_type.html#details">More...</a><br /></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="typedef-members"></a>
Typedefs</h2></td></tr>
<tr class="memitem:ga9a6b7719f0613ba9e2c93cffd97ebfc0"><td class="memItemLeft" align="right" valign="top">typedef struct <a class="el" href="group___neural_networks.html#ga9a6b7719f0613ba9e2c93cffd97ebfc0">ANeuralNetworksMemory</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga9a6b7719f0613ba9e2c93cffd97ebfc0">ANeuralNetworksMemory</a></td></tr>
<tr class="memdesc:ga9a6b7719f0613ba9e2c93cffd97ebfc0"><td class="mdescLeft">&#160;</td><td class="mdescRight">ANeuralNetworksMemory is an opaque type that represents memory.  <a href="#ga9a6b7719f0613ba9e2c93cffd97ebfc0">More...</a><br /></td></tr>
<tr class="separator:ga9a6b7719f0613ba9e2c93cffd97ebfc0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga4ce6f20a94d3a2de47fa5a810feeb9a4"><td class="memItemLeft" align="right" valign="top">typedef struct <a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a></td></tr>
<tr class="memdesc:ga4ce6f20a94d3a2de47fa5a810feeb9a4"><td class="mdescLeft">&#160;</td><td class="mdescRight">ANeuralNetworksModel is an opaque type that contains a description of the mathematical operations that constitute the model.  <a href="#ga4ce6f20a94d3a2de47fa5a810feeb9a4">More...</a><br /></td></tr>
<tr class="separator:ga4ce6f20a94d3a2de47fa5a810feeb9a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaaea7d6481c0077bf9547fdb887b55fe6"><td class="memItemLeft" align="right" valign="top">typedef struct <a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a></td></tr>
<tr class="memdesc:gaaea7d6481c0077bf9547fdb887b55fe6"><td class="mdescLeft">&#160;</td><td class="mdescRight">ANeuralNetworksCompilation is an opaque type that can be used to compile a machine learning model.  <a href="#gaaea7d6481c0077bf9547fdb887b55fe6">More...</a><br /></td></tr>
<tr class="separator:gaaea7d6481c0077bf9547fdb887b55fe6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gace4c4f3201c32eba9d18850e86dea33b"><td class="memItemLeft" align="right" valign="top">typedef struct <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a></td></tr>
<tr class="memdesc:gace4c4f3201c32eba9d18850e86dea33b"><td class="mdescLeft">&#160;</td><td class="mdescRight">ANeuralNetworksExecution is an opaque type that can be used to apply a machine learning model to a set of inputs.  <a href="#gace4c4f3201c32eba9d18850e86dea33b">More...</a><br /></td></tr>
<tr class="separator:gace4c4f3201c32eba9d18850e86dea33b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaf2dc08c1084c170b255608f41d26297f"><td class="memItemLeft" align="right" valign="top">typedef struct <a class="el" href="struct_a_neural_networks_operand_type.html">ANeuralNetworksOperandType</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#gaf2dc08c1084c170b255608f41d26297f">ANeuralNetworksOperandType</a></td></tr>
<tr class="memdesc:gaf2dc08c1084c170b255608f41d26297f"><td class="mdescLeft">&#160;</td><td class="mdescRight"><a class="el" href="struct_a_neural_networks_operand_type.html" title="ANeuralNetworksOperandType describes the type of an operand. ">ANeuralNetworksOperandType</a> describes the type of an operand.  <a href="#gaf2dc08c1084c170b255608f41d26297f">More...</a><br /></td></tr>
<tr class="separator:gaf2dc08c1084c170b255608f41d26297f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga1aa0c2cbc257093f98d6f0a2eb1932a5"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ga1aa0c2cbc257093f98d6f0a2eb1932a5"></a>
typedef int32_t&#160;</td><td class="memItemRight" valign="bottom"><b>ANeuralNetworksOperationType</b></td></tr>
<tr class="separator:ga1aa0c2cbc257093f98d6f0a2eb1932a5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga8b595e8510f91fa0f7d9eaa09fe6c269"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ga8b595e8510f91fa0f7d9eaa09fe6c269"></a>
typedef struct <a class="el" href="group___neural_networks.html#ga8b595e8510f91fa0f7d9eaa09fe6c269">ANeuralNetworksEvent</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga8b595e8510f91fa0f7d9eaa09fe6c269">ANeuralNetworksEvent</a></td></tr>
<tr class="memdesc:ga8b595e8510f91fa0f7d9eaa09fe6c269"><td class="mdescLeft">&#160;</td><td class="mdescRight">ANeuralNetworksEvent is an opaque type that represents an event that will be signaled once an execution completes. <br /></td></tr>
<tr class="separator:ga8b595e8510f91fa0f7d9eaa09fe6c269"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="enum-members"></a>
Enumerations</h2></td></tr>
<tr class="memitem:gaf06d1affd33f3bc698d0c04eceb23298"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#gaf06d1affd33f3bc698d0c04eceb23298">OperandCode</a> { <br />
&#160;&#160;<a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a6aa658f93a72ca7356d9433f772ef578">ANEURALNETWORKS_FLOAT32</a> = 0, 
<a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298acb165f692e9d189c820ceba84b3c21dc">ANEURALNETWORKS_INT32</a> = 1, 
<a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298ad392906165c1e93c2a9719998d65223c">ANEURALNETWORKS_UINT32</a> = 2, 
<a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a> = 3, 
<br />
&#160;&#160;<a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298ac34965d8e76ac5acfddf5acd9e40f896">ANEURALNETWORKS_TENSOR_INT32</a> = 4, 
<a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a> = 5
<br />
 }<tr class="memdesc:gaf06d1affd33f3bc698d0c04eceb23298"><td class="mdescLeft">&#160;</td><td class="mdescRight">Operand types.  <a href="group___neural_networks.html#gaf06d1affd33f3bc698d0c04eceb23298">More...</a><br /></td></tr>
</td></tr>
<tr class="separator:gaf06d1affd33f3bc698d0c04eceb23298"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaabbe492c60331b13038e39d4207940e0"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#gaabbe492c60331b13038e39d4207940e0">OperationCode</a> { <br />
&#160;&#160;<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0ad681988001e5f8ab73230a311f4ab034">ANEURALNETWORKS_ADD</a> = 0, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0a12e6b53aadbd3736c38f1a159adea788">ANEURALNETWORKS_AVERAGE_POOL_2D</a> = 1, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0a44cbea825c4b224dd3ea757e9b1f65ed">ANEURALNETWORKS_CONCATENATION</a> = 2, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0a34a73b5eaf458b67db5eda71557d1d01">ANEURALNETWORKS_CONV_2D</a> = 3, 
<br />
&#160;&#160;<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0a2b49a44b7ebba243fad01556c1f0392e">ANEURALNETWORKS_DEPTHWISE_CONV_2D</a> = 4, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0a34253f8b844b4c143f0fa36be3ba3f7a">ANEURALNETWORKS_DEPTH_TO_SPACE</a> = 5, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0ad4c9300b061d9d14669bd5acdc7538e2">ANEURALNETWORKS_DEQUANTIZE</a> = 6, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0a8d2ada77adb74357fc0770405bca0e3c">ANEURALNETWORKS_EMBEDDING_LOOKUP</a> = 7, 
<br />
&#160;&#160;<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0acdb4a57160153118dc6f87af0e4eccc5">ANEURALNETWORKS_FLOOR</a> = 8, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0aaada7a3dbaf4676aba560c933ff610c5">ANEURALNETWORKS_FULLY_CONNECTED</a> = 9, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0aca92716c8c73c1f0fa7f0757916fee26">ANEURALNETWORKS_HASHTABLE_LOOKUP</a> = 10, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0abf295dee59560ff29d435226ec4c24bd">ANEURALNETWORKS_L2_NORMALIZATION</a> = 11, 
<br />
&#160;&#160;<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0a2fb636e30d8853f9fa1a395e30660e92">ANEURALNETWORKS_L2_POOL_2D</a> = 12, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0a876ccb0f3e6555637c5e278a7715fc05">ANEURALNETWORKS_LOCAL_RESPONSE_NORMALIZATION</a> = 13, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0a82a340eb540933f638db420369650483">ANEURALNETWORKS_LOGISTIC</a> = 14, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0a800cdcec5d7ba776789cb2d1ef669965">ANEURALNETWORKS_LSH_PROJECTION</a> = 15, 
<br />
&#160;&#160;<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0ad0377e8c305e596fb7f64ff896671fc5">ANEURALNETWORKS_LSTM</a> = 16, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0a0f227a4d98ad5af31f7fd4d255d246ce">ANEURALNETWORKS_MAX_POOL_2D</a> = 17, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0ab34ca99890c827b536ce66256a803d7a">ANEURALNETWORKS_MUL</a> = 18, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0abb2f979866b131c5089ba0caaecee656">ANEURALNETWORKS_RELU</a> = 19, 
<br />
&#160;&#160;<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0a73b9a2ded1dda2925d2e73aec44d2e2e">ANEURALNETWORKS_RELU1</a> = 20, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0a04a24c2d6f0aac4c3f5324c1d7764714">ANEURALNETWORKS_RELU6</a> = 21, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0a535e7e99383ee49456c8671843b93a59">ANEURALNETWORKS_RESHAPE</a> = 22, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0a42bd92518e273b6716ecd56b571fcd3e">ANEURALNETWORKS_RESIZE_BILINEAR</a> = 23, 
<br />
&#160;&#160;<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0acd2684ac9c73bb29767b534e78a332e8">ANEURALNETWORKS_RNN</a> = 24, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0a2bfbb83a537701e2843a3d5004250c2c">ANEURALNETWORKS_SOFTMAX</a> = 25, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0a90099ec472f6571a932b111d979dcccd">ANEURALNETWORKS_SPACE_TO_DEPTH</a> = 26, 
<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0a7096de21038c1ce49d354a00cba7b552">ANEURALNETWORKS_SVDF</a> = 27, 
<br />
&#160;&#160;<a class="el" href="group___neural_networks.html#ggaabbe492c60331b13038e39d4207940e0a4b63c9caab823f112d82d853a77381e5">ANEURALNETWORKS_TANH</a> = 28
<br />
 }<tr class="memdesc:gaabbe492c60331b13038e39d4207940e0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Operation types.  <a href="group___neural_networks.html#gaabbe492c60331b13038e39d4207940e0">More...</a><br /></td></tr>
</td></tr>
<tr class="separator:gaabbe492c60331b13038e39d4207940e0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga4ec620045a39909a6bf00b3ee0c4d414"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga4ec620045a39909a6bf00b3ee0c4d414">FuseCode</a> { <a class="el" href="group___neural_networks.html#gga4ec620045a39909a6bf00b3ee0c4d414a0f7344826e8abfa2ba90c82e856dc4f9">ANEURALNETWORKS_FUSED_NONE</a> = 0, 
<a class="el" href="group___neural_networks.html#gga4ec620045a39909a6bf00b3ee0c4d414abfcb75d9fb70f78934766b830d98d7d6">ANEURALNETWORKS_FUSED_RELU</a> = 1, 
<a class="el" href="group___neural_networks.html#gga4ec620045a39909a6bf00b3ee0c4d414a9c969b9474ae51f8ecc544e11fbb8303">ANEURALNETWORKS_FUSED_RELU1</a> = 2, 
<a class="el" href="group___neural_networks.html#gga4ec620045a39909a6bf00b3ee0c4d414a29b9372bc4e003e080ef85342fd6c429">ANEURALNETWORKS_FUSED_RELU6</a> = 3
 }<tr class="memdesc:ga4ec620045a39909a6bf00b3ee0c4d414"><td class="mdescLeft">&#160;</td><td class="mdescRight">Fused activation function types.  <a href="group___neural_networks.html#ga4ec620045a39909a6bf00b3ee0c4d414">More...</a><br /></td></tr>
</td></tr>
<tr class="separator:ga4ec620045a39909a6bf00b3ee0c4d414"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab72e9e6263fd5b015bb7f41ec18ce220"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#gab72e9e6263fd5b015bb7f41ec18ce220">PaddingCode</a> { <a class="el" href="group___neural_networks.html#ggab72e9e6263fd5b015bb7f41ec18ce220af941cf111bcdf02b706e6290310ded19">ANEURALNETWORKS_PADDING_SAME</a> = 1, 
<a class="el" href="group___neural_networks.html#ggab72e9e6263fd5b015bb7f41ec18ce220a0744f0fca811cc952ae983d689dbc4d8">ANEURALNETWORKS_PADDING_VALID</a> = 2
 }<tr class="memdesc:gab72e9e6263fd5b015bb7f41ec18ce220"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implicit padding algorithms.  <a href="group___neural_networks.html#gab72e9e6263fd5b015bb7f41ec18ce220">More...</a><br /></td></tr>
</td></tr>
<tr class="separator:gab72e9e6263fd5b015bb7f41ec18ce220"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga034380829226e2d980b2a7e63c992f18"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga034380829226e2d980b2a7e63c992f18">PreferenceCode</a> { <a class="el" href="group___neural_networks.html#gga034380829226e2d980b2a7e63c992f18a370c42db64448662ad79116556bcec01">ANEURALNETWORKS_PREFER_LOW_POWER</a> = 0, 
<a class="el" href="group___neural_networks.html#gga034380829226e2d980b2a7e63c992f18af7fff807061a3e9358364a502691d887">ANEURALNETWORKS_PREFER_FAST_SINGLE_ANSWER</a> = 1, 
<a class="el" href="group___neural_networks.html#gga034380829226e2d980b2a7e63c992f18af727c25f1e2d8dcc693c477aef4ea5f5">ANEURALNETWORKS_PREFER_SUSTAINED_SPEED</a> = 2
 }<tr class="memdesc:ga034380829226e2d980b2a7e63c992f18"><td class="mdescLeft">&#160;</td><td class="mdescRight">Execution preferences.  <a href="group___neural_networks.html#ga034380829226e2d980b2a7e63c992f18">More...</a><br /></td></tr>
</td></tr>
<tr class="separator:ga034380829226e2d980b2a7e63c992f18"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad8097859ab1bdd06be52a8421df152d4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="gad8097859ab1bdd06be52a8421df152d4"></a>enum &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#gad8097859ab1bdd06be52a8421df152d4">ResultCode</a> { <br />
&#160;&#160;<b>ANEURALNETWORKS_NO_ERROR</b> = 0, 
<b>ANEURALNETWORKS_OUT_OF_MEMORY</b> = 1, 
<b>ANEURALNETWORKS_INCOMPLETE</b> = 2, 
<b>ANEURALNETWORKS_UNEXPECTED_NULL</b> = 3, 
<br />
&#160;&#160;<b>ANEURALNETWORKS_BAD_DATA</b> = 4, 
<b>ANEURALNETWORKS_OP_FAILED</b> = 5, 
<b>ANEURALNETWORKS_UNMAPPABLE</b> = 5, 
<b>ANEURALNETWORKS_BAD_STATE</b> = 6
<br />
 }<tr class="memdesc:gad8097859ab1bdd06be52a8421df152d4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Result codes. <br /></td></tr>
</td></tr>
<tr class="separator:gad8097859ab1bdd06be52a8421df152d4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gadc29c2ff13d900c2f185ee95427fb06c"><td class="memItemLeft" align="right" valign="top">enum &#160;</td><td class="memItemRight" valign="bottom">{ <b>ANEURALNETWORKS_MAX_SIZE_OF_IMMEDIATELY_COPIED_VALUES</b> = 128
 }<tr class="memdesc:gadc29c2ff13d900c2f185ee95427fb06c"><td class="mdescLeft">&#160;</td><td class="mdescRight">For <a class="el" href="group___neural_networks.html#gab95e96267e0f955086b87a743dad44ca">ANeuralNetworksModel_setOperandValue</a>, values with a length smaller or equal to this will be immediately copied into the model.  <a href="group___neural_networks.html#gadc29c2ff13d900c2f185ee95427fb06c">More...</a><br /></td></tr>
</td></tr>
<tr class="separator:gadc29c2ff13d900c2f185ee95427fb06c"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ga3510b07da0ab9626fb84688fb91112be"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga3510b07da0ab9626fb84688fb91112be">ANeuralNetworksMemory_createFromFd</a> (size_t size, int protect, int fd, size_t offset, <a class="el" href="group___neural_networks.html#ga9a6b7719f0613ba9e2c93cffd97ebfc0">ANeuralNetworksMemory</a> **memory)</td></tr>
<tr class="memdesc:ga3510b07da0ab9626fb84688fb91112be"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates a shared memory object from a file descriptor.  <a href="#ga3510b07da0ab9626fb84688fb91112be">More...</a><br /></td></tr>
<tr class="separator:ga3510b07da0ab9626fb84688fb91112be"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga5ec77f5e69b20fac270eaeae2f8e0cb8"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga5ec77f5e69b20fac270eaeae2f8e0cb8">ANeuralNetworksMemory_free</a> (<a class="el" href="group___neural_networks.html#ga9a6b7719f0613ba9e2c93cffd97ebfc0">ANeuralNetworksMemory</a> *memory)</td></tr>
<tr class="memdesc:ga5ec77f5e69b20fac270eaeae2f8e0cb8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Delete a memory object.  <a href="#ga5ec77f5e69b20fac270eaeae2f8e0cb8">More...</a><br /></td></tr>
<tr class="separator:ga5ec77f5e69b20fac270eaeae2f8e0cb8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga8142daaf804adc33fea8e44af2ba2307"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga8142daaf804adc33fea8e44af2ba2307">ANeuralNetworksModel_create</a> (<a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> **model)</td></tr>
<tr class="memdesc:ga8142daaf804adc33fea8e44af2ba2307"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create an empty <a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a>.  <a href="#ga8142daaf804adc33fea8e44af2ba2307">More...</a><br /></td></tr>
<tr class="separator:ga8142daaf804adc33fea8e44af2ba2307"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2287b1751678d75a349faa36956602fb"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga2287b1751678d75a349faa36956602fb">ANeuralNetworksModel_free</a> (<a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> *model)</td></tr>
<tr class="memdesc:ga2287b1751678d75a349faa36956602fb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destroy a model.  <a href="#ga2287b1751678d75a349faa36956602fb">More...</a><br /></td></tr>
<tr class="separator:ga2287b1751678d75a349faa36956602fb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga2324b730b593482fda8f8f3a129ba06d"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga2324b730b593482fda8f8f3a129ba06d">ANeuralNetworksModel_finish</a> (<a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> *model)</td></tr>
<tr class="memdesc:ga2324b730b593482fda8f8f3a129ba06d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Indicate that we have finished modifying a model.  <a href="#ga2324b730b593482fda8f8f3a129ba06d">More...</a><br /></td></tr>
<tr class="separator:ga2324b730b593482fda8f8f3a129ba06d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab4bf35bfd0530a80c1cbd38294bc3007"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#gab4bf35bfd0530a80c1cbd38294bc3007">ANeuralNetworksModel_addOperand</a> (<a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> *model, const <a class="el" href="struct_a_neural_networks_operand_type.html">ANeuralNetworksOperandType</a> *type)</td></tr>
<tr class="memdesc:gab4bf35bfd0530a80c1cbd38294bc3007"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add an operand to a model.  <a href="#gab4bf35bfd0530a80c1cbd38294bc3007">More...</a><br /></td></tr>
<tr class="separator:gab4bf35bfd0530a80c1cbd38294bc3007"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab95e96267e0f955086b87a743dad44ca"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#gab95e96267e0f955086b87a743dad44ca">ANeuralNetworksModel_setOperandValue</a> (<a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> *model, int32_t index, const void *buffer, size_t length)</td></tr>
<tr class="memdesc:gab95e96267e0f955086b87a743dad44ca"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets an operand to a constant value.  <a href="#gab95e96267e0f955086b87a743dad44ca">More...</a><br /></td></tr>
<tr class="separator:gab95e96267e0f955086b87a743dad44ca"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gadd7a4261e062051516fd49c7217c20b8"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#gadd7a4261e062051516fd49c7217c20b8">ANeuralNetworksModel_setOperandValueFromMemory</a> (<a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> *model, int32_t index, const <a class="el" href="group___neural_networks.html#ga9a6b7719f0613ba9e2c93cffd97ebfc0">ANeuralNetworksMemory</a> *memory, size_t offset, size_t length)</td></tr>
<tr class="memdesc:gadd7a4261e062051516fd49c7217c20b8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets an operand to a value stored in a memory object.  <a href="#gadd7a4261e062051516fd49c7217c20b8">More...</a><br /></td></tr>
<tr class="separator:gadd7a4261e062051516fd49c7217c20b8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga5cf00af11c3bd21d27c0dff6ed7a15be"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga5cf00af11c3bd21d27c0dff6ed7a15be">ANeuralNetworksModel_addOperation</a> (<a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> *model, ANeuralNetworksOperationType type, uint32_t inputCount, const uint32_t *inputs, uint32_t outputCount, const uint32_t *outputs)</td></tr>
<tr class="memdesc:ga5cf00af11c3bd21d27c0dff6ed7a15be"><td class="mdescLeft">&#160;</td><td class="mdescRight">Add an operation to a model.  <a href="#ga5cf00af11c3bd21d27c0dff6ed7a15be">More...</a><br /></td></tr>
<tr class="separator:ga5cf00af11c3bd21d27c0dff6ed7a15be"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga9bb7cd668b49da24e0c70ee6bf237a40"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga9bb7cd668b49da24e0c70ee6bf237a40">ANeuralNetworksModel_identifyInputsAndOutputs</a> (<a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> *model, uint32_t inputCount, const uint32_t *inputs, uint32_t outputCount, const uint32_t *outputs)</td></tr>
<tr class="memdesc:ga9bb7cd668b49da24e0c70ee6bf237a40"><td class="mdescLeft">&#160;</td><td class="mdescRight">Specfifies which operands will be the model's inputs and outputs.  <a href="#ga9bb7cd668b49da24e0c70ee6bf237a40">More...</a><br /></td></tr>
<tr class="separator:ga9bb7cd668b49da24e0c70ee6bf237a40"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga10451d74cade530ceb163a2d6f7508f0"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga10451d74cade530ceb163a2d6f7508f0">ANeuralNetworksCompilation_create</a> (<a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> *model, <a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a> **compilation)</td></tr>
<tr class="memdesc:ga10451d74cade530ceb163a2d6f7508f0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create a <a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a> to compile the given model.  <a href="#ga10451d74cade530ceb163a2d6f7508f0">More...</a><br /></td></tr>
<tr class="separator:ga10451d74cade530ceb163a2d6f7508f0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab62e33fbdc133bc6c4bde11fcaec2234"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#gab62e33fbdc133bc6c4bde11fcaec2234">ANeuralNetworksCompilation_free</a> (<a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a> *compilation)</td></tr>
<tr class="memdesc:gab62e33fbdc133bc6c4bde11fcaec2234"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destroy a compilation.  <a href="#gab62e33fbdc133bc6c4bde11fcaec2234">More...</a><br /></td></tr>
<tr class="separator:gab62e33fbdc133bc6c4bde11fcaec2234"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga538ce3c0113ed3b54af97cf491815df3"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga538ce3c0113ed3b54af97cf491815df3">ANeuralNetworksCompilation_setPreference</a> (<a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a> *compilation, int32_t preference)</td></tr>
<tr class="memdesc:ga538ce3c0113ed3b54af97cf491815df3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the execution preference.  <a href="#ga538ce3c0113ed3b54af97cf491815df3">More...</a><br /></td></tr>
<tr class="separator:ga538ce3c0113ed3b54af97cf491815df3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaa9fe0549c392bd3cfdbfc05182679864"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#gaa9fe0549c392bd3cfdbfc05182679864">ANeuralNetworksCompilation_finish</a> (<a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a> *compilation)</td></tr>
<tr class="memdesc:gaa9fe0549c392bd3cfdbfc05182679864"><td class="mdescLeft">&#160;</td><td class="mdescRight">Indicate that we have finished modifying a compilation.  <a href="#gaa9fe0549c392bd3cfdbfc05182679864">More...</a><br /></td></tr>
<tr class="separator:gaa9fe0549c392bd3cfdbfc05182679864"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga1079439ec94c91b9a0d60005d6bad576"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga1079439ec94c91b9a0d60005d6bad576">ANeuralNetworksExecution_create</a> (<a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a> *compilation, <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> **execution)</td></tr>
<tr class="memdesc:ga1079439ec94c91b9a0d60005d6bad576"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create a <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> to apply the given compilation.  <a href="#ga1079439ec94c91b9a0d60005d6bad576">More...</a><br /></td></tr>
<tr class="separator:ga1079439ec94c91b9a0d60005d6bad576"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga4472907d12644156ec45935be26c0852"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga4472907d12644156ec45935be26c0852">ANeuralNetworksExecution_free</a> (<a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> *execution)</td></tr>
<tr class="memdesc:ga4472907d12644156ec45935be26c0852"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destroy an execution.  <a href="#ga4472907d12644156ec45935be26c0852">More...</a><br /></td></tr>
<tr class="separator:ga4472907d12644156ec45935be26c0852"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaf5540f8785a31b550ba7e7a78eed6a85"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#gaf5540f8785a31b550ba7e7a78eed6a85">ANeuralNetworksExecution_setInput</a> (<a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> *execution, int32_t index, const <a class="el" href="struct_a_neural_networks_operand_type.html">ANeuralNetworksOperandType</a> *type, const void *buffer, size_t length)</td></tr>
<tr class="memdesc:gaf5540f8785a31b550ba7e7a78eed6a85"><td class="mdescLeft">&#160;</td><td class="mdescRight">Associate a user buffer with an input of the model of the <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a>.  <a href="#gaf5540f8785a31b550ba7e7a78eed6a85">More...</a><br /></td></tr>
<tr class="separator:gaf5540f8785a31b550ba7e7a78eed6a85"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="var-members"></a>
Variables</h2></td></tr>
<tr class="memitem:gaebe0bf8514de064d1d68e8857a3dccfd"><td class="memItemLeft" align="right" valign="top">int32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#gaebe0bf8514de064d1d68e8857a3dccfd">ANeuralNetworksOperandType::type</a></td></tr>
<tr class="memdesc:gaebe0bf8514de064d1d68e8857a3dccfd"><td class="mdescLeft">&#160;</td><td class="mdescRight">The data type, e.g ANEURALNETWORKS_INT8.  <a href="#gaebe0bf8514de064d1d68e8857a3dccfd">More...</a><br /></td></tr>
<tr class="separator:gaebe0bf8514de064d1d68e8857a3dccfd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga8e9b0f8229777661e6005b9d1847f026"><td class="memItemLeft" align="right" valign="top">uint32_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga8e9b0f8229777661e6005b9d1847f026">ANeuralNetworksOperandType::dimensionCount</a></td></tr>
<tr class="memdesc:ga8e9b0f8229777661e6005b9d1847f026"><td class="mdescLeft">&#160;</td><td class="mdescRight">The number of dimensions.  <a href="#ga8e9b0f8229777661e6005b9d1847f026">More...</a><br /></td></tr>
<tr class="separator:ga8e9b0f8229777661e6005b9d1847f026"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga6d70bf7a7ea5d2e61e674cf7b3393548"><td class="memItemLeft" align="right" valign="top">const uint32_t *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga6d70bf7a7ea5d2e61e674cf7b3393548">ANeuralNetworksOperandType::dimensions</a></td></tr>
<tr class="memdesc:ga6d70bf7a7ea5d2e61e674cf7b3393548"><td class="mdescLeft">&#160;</td><td class="mdescRight">The dimensions of the tensor.  <a href="#ga6d70bf7a7ea5d2e61e674cf7b3393548">More...</a><br /></td></tr>
<tr class="separator:ga6d70bf7a7ea5d2e61e674cf7b3393548"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaee95637670d7b7179b28a9d5a22f621a"><td class="memItemLeft" align="right" valign="top">float&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#gaee95637670d7b7179b28a9d5a22f621a">ANeuralNetworksOperandType::scale</a></td></tr>
<tr class="memdesc:gaee95637670d7b7179b28a9d5a22f621a"><td class="mdescLeft">&#160;</td><td class="mdescRight">These two fields are only used for quantized tensors.  <a href="#gaee95637670d7b7179b28a9d5a22f621a">More...</a><br /></td></tr>
<tr class="separator:gaee95637670d7b7179b28a9d5a22f621a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gad7e11ae6e4a5c0e338cfe5c9a1e9dbe8"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="gad7e11ae6e4a5c0e338cfe5c9a1e9dbe8"></a>
int32_t&#160;</td><td class="memItemRight" valign="bottom"><b>ANeuralNetworksOperandType::zeroPoint</b></td></tr>
<tr class="separator:gad7e11ae6e4a5c0e338cfe5c9a1e9dbe8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaa8a30670b12f540765f00b1b6d3be011"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#gaa8a30670b12f540765f00b1b6d3be011">ANeuralNetworksExecution_setInputFromMemory</a> (<a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> *execution, int32_t index, const <a class="el" href="struct_a_neural_networks_operand_type.html">ANeuralNetworksOperandType</a> *type, const <a class="el" href="group___neural_networks.html#ga9a6b7719f0613ba9e2c93cffd97ebfc0">ANeuralNetworksMemory</a> *memory, size_t offset, size_t length)</td></tr>
<tr class="memdesc:gaa8a30670b12f540765f00b1b6d3be011"><td class="mdescLeft">&#160;</td><td class="mdescRight">Associate part of a memory object with an input of the model of the <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a>.  <a href="#gaa8a30670b12f540765f00b1b6d3be011">More...</a><br /></td></tr>
<tr class="separator:gaa8a30670b12f540765f00b1b6d3be011"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga16ce3c18aa2574df91f7b7932bfdf48d"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga16ce3c18aa2574df91f7b7932bfdf48d">ANeuralNetworksExecution_setOutput</a> (<a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> *execution, int32_t index, const <a class="el" href="struct_a_neural_networks_operand_type.html">ANeuralNetworksOperandType</a> *type, void *buffer, size_t length)</td></tr>
<tr class="memdesc:ga16ce3c18aa2574df91f7b7932bfdf48d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Associate a user buffer with an output of the model of the <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a>.  <a href="#ga16ce3c18aa2574df91f7b7932bfdf48d">More...</a><br /></td></tr>
<tr class="separator:ga16ce3c18aa2574df91f7b7932bfdf48d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga379a9efd313e22d7d8e1e1bef7c0defb"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga379a9efd313e22d7d8e1e1bef7c0defb">ANeuralNetworksExecution_setOutputFromMemory</a> (<a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> *execution, int32_t index, const <a class="el" href="struct_a_neural_networks_operand_type.html">ANeuralNetworksOperandType</a> *type, const <a class="el" href="group___neural_networks.html#ga9a6b7719f0613ba9e2c93cffd97ebfc0">ANeuralNetworksMemory</a> *memory, size_t offset, size_t length)</td></tr>
<tr class="memdesc:ga379a9efd313e22d7d8e1e1bef7c0defb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Associate part of a memory object with an output of the model of the <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a>.  <a href="#ga379a9efd313e22d7d8e1e1bef7c0defb">More...</a><br /></td></tr>
<tr class="separator:ga379a9efd313e22d7d8e1e1bef7c0defb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga54c60b23afdfff211fc30ef746a2d9e6"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#ga54c60b23afdfff211fc30ef746a2d9e6">ANeuralNetworksExecution_startCompute</a> (<a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> *execution, <a class="el" href="group___neural_networks.html#ga8b595e8510f91fa0f7d9eaa09fe6c269">ANeuralNetworksEvent</a> **event)</td></tr>
<tr class="memdesc:ga54c60b23afdfff211fc30ef746a2d9e6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Schedule evaluation of the execution.  <a href="#ga54c60b23afdfff211fc30ef746a2d9e6">More...</a><br /></td></tr>
<tr class="separator:ga54c60b23afdfff211fc30ef746a2d9e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab6569a95097d55d2bd04e789faca1a78"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#gab6569a95097d55d2bd04e789faca1a78">ANeuralNetworksEvent_wait</a> (<a class="el" href="group___neural_networks.html#ga8b595e8510f91fa0f7d9eaa09fe6c269">ANeuralNetworksEvent</a> *event)</td></tr>
<tr class="memdesc:gab6569a95097d55d2bd04e789faca1a78"><td class="mdescLeft">&#160;</td><td class="mdescRight">Waits until the execution completes.  <a href="#gab6569a95097d55d2bd04e789faca1a78">More...</a><br /></td></tr>
<tr class="separator:gab6569a95097d55d2bd04e789faca1a78"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab0f751c3202a28515371d447c43d97aa"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group___neural_networks.html#gab0f751c3202a28515371d447c43d97aa">ANeuralNetworksEvent_free</a> (<a class="el" href="group___neural_networks.html#ga8b595e8510f91fa0f7d9eaa09fe6c269">ANeuralNetworksEvent</a> *event)</td></tr>
<tr class="memdesc:gab0f751c3202a28515371d447c43d97aa"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destroys the event.  <a href="#gab0f751c3202a28515371d447c43d97aa">More...</a><br /></td></tr>
<tr class="separator:gab0f751c3202a28515371d447c43d97aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<h2 class="groupheader">Typedef Documentation</h2>
<a class="anchor" id="gaaea7d6481c0077bf9547fdb887b55fe6"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">typedef struct <a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a> <a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>ANeuralNetworksCompilation is an opaque type that can be used to compile a machine learning model. </p>
<p>To use:</p><ul>
<li>
Create a new compilation instance by calling the <a class="el" href="group___neural_networks.html#ga10451d74cade530ceb163a2d6f7508f0">ANeuralNetworksCompilation_create</a> function. </li>
<li>
Set any desired properties on the compilation (for example, <a class="el" href="group___neural_networks.html#ga538ce3c0113ed3b54af97cf491815df3">ANeuralNetworksCompilation_setPreference</a>). </li>
<li>
Complete the compilation with <a class="el" href="group___neural_networks.html#gaa9fe0549c392bd3cfdbfc05182679864">ANeuralNetworksCompilation_finish</a>. </li>
<li>
Use the compilation as many times as needed with <a class="el" href="group___neural_networks.html#ga1079439ec94c91b9a0d60005d6bad576">ANeuralNetworksExecution_create</a>. </li>
<li>
Destroy the compilation with <a class="el" href="group___neural_networks.html#gab62e33fbdc133bc6c4bde11fcaec2234">ANeuralNetworksCompilation_free</a> once all executions using the compilation have completed.</li>
</ul>
<p>A compilation is completed by calling <a class="el" href="group___neural_networks.html#gaa9fe0549c392bd3cfdbfc05182679864">ANeuralNetworksCompilation_finish</a>. A compilation is destroyed by calling <a class="el" href="group___neural_networks.html#gab62e33fbdc133bc6c4bde11fcaec2234">ANeuralNetworksCompilation_free</a>.</p>
<p>A compilation cannot be modified once <a class="el" href="group___neural_networks.html#gaa9fe0549c392bd3cfdbfc05182679864">ANeuralNetworksCompilation_finish</a> has been called on it.</p>
<p>It is the application's responsibility to make sure that only one thread modifies a compilation at a given time. It is however safe for more than one thread to use the compilation once <a class="el" href="group___neural_networks.html#gaa9fe0549c392bd3cfdbfc05182679864">ANeuralNetworksCompilation_finish</a> has returned.</p>
<p>It is also the application's responsibility to ensure that there are no other uses of the compilation after calling <a class="el" href="group___neural_networks.html#gab62e33fbdc133bc6c4bde11fcaec2234">ANeuralNetworksCompilation_free</a>. This includes any execution object created using the compilation.</p>

<p>Definition at line <a class="el" href="_neural_networks_8h_source.html#l01334">1334</a> of file <a class="el" href="_neural_networks_8h_source.html">NeuralNetworks.h</a>.</p>

</div>
</div>
<a class="anchor" id="gace4c4f3201c32eba9d18850e86dea33b"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">typedef struct <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>ANeuralNetworksExecution is an opaque type that can be used to apply a machine learning model to a set of inputs. </p>
<p>To use:</p><ul>
<li>
Create a new execution instance by calling the <a class="el" href="group___neural_networks.html#ga1079439ec94c91b9a0d60005d6bad576">ANeuralNetworksExecution_create</a> function. </li>
<li>
Associate data to the model inputs with <a class="el" href="group___neural_networks.html#gaf5540f8785a31b550ba7e7a78eed6a85">ANeuralNetworksExecution_setInput</a> or <a class="el" href="group___neural_networks.html#gaa8a30670b12f540765f00b1b6d3be011">ANeuralNetworksExecution_setInputFromMemory</a>. </li>
<li>
Associate output buffers to the model outputs with <a class="el" href="group___neural_networks.html#ga16ce3c18aa2574df91f7b7932bfdf48d">ANeuralNetworksExecution_setOutput</a> or <a class="el" href="group___neural_networks.html#ga379a9efd313e22d7d8e1e1bef7c0defb">ANeuralNetworksExecution_setOutputFromMemory</a>. </li>
<li>
Apply the model with <a class="el" href="group___neural_networks.html#ga54c60b23afdfff211fc30ef746a2d9e6">ANeuralNetworksExecution_startCompute</a>. </li>
<li>
Wait for the execution to complete with <a class="el" href="group___neural_networks.html#gab6569a95097d55d2bd04e789faca1a78">ANeuralNetworksEvent_wait</a>. </li>
<li>
Destroy the execution with <a class="el" href="group___neural_networks.html#ga4472907d12644156ec45935be26c0852">ANeuralNetworksExecution_free</a>.</li>
</ul>
<p>An execution cannot be modified once <a class="el" href="group___neural_networks.html#ga54c60b23afdfff211fc30ef746a2d9e6">ANeuralNetworksExecution_startCompute</a> has been called on it.</p>
<p>An execution can be applied to a model with <a class="el" href="group___neural_networks.html#ga54c60b23afdfff211fc30ef746a2d9e6">ANeuralNetworksExecution_startCompute</a> only once. Create new executions to do new evaluations of the model.</p>
<p>It is the application's responsibility to make sure that only one thread modifies an execution at a given time. It is however safe for more than one thread to use <a class="el" href="group___neural_networks.html#gab6569a95097d55d2bd04e789faca1a78">ANeuralNetworksEvent_wait</a> at the same time.</p>
<p>It is also the application's responsibility to ensure that there are no other uses of the request after calling <a class="el" href="group___neural_networks.html#ga4472907d12644156ec45935be26c0852">ANeuralNetworksExecution_free</a>.</p>

<p>Definition at line <a class="el" href="_neural_networks_8h_source.html#l01369">1369</a> of file <a class="el" href="_neural_networks_8h_source.html">NeuralNetworks.h</a>.</p>

</div>
</div>
<a class="anchor" id="ga9a6b7719f0613ba9e2c93cffd97ebfc0"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">typedef struct <a class="el" href="group___neural_networks.html#ga9a6b7719f0613ba9e2c93cffd97ebfc0">ANeuralNetworksMemory</a> <a class="el" href="group___neural_networks.html#ga9a6b7719f0613ba9e2c93cffd97ebfc0">ANeuralNetworksMemory</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>ANeuralNetworksMemory is an opaque type that represents memory. </p>
<p>This type is used to represent shared memory, memory mapped files, and similar memories.</p>
<p>By using shared memory, a program can efficiently communicate to the runtime and drivers the tensors that define a model. See <a class="el" href="group___neural_networks.html#gadd7a4261e062051516fd49c7217c20b8">ANeuralNetworksModel_setOperandValueFromMemory</a>. An application should typically create one shared memory object that contains every tensor needed to define a model. <a class="el" href="group___neural_networks.html#ga3510b07da0ab9626fb84688fb91112be">ANeuralNetworksMemory_createFromFd</a> can be used to create shared memory from a file handle. <a class="el" href="">ANeuralNetworksMemory_createShared</a> can be used to directly created shared memory.</p>
<p>Memory objects can also be used to specify the input and output arguments of an execution. See <a class="el" href="group___neural_networks.html#gaa8a30670b12f540765f00b1b6d3be011">ANeuralNetworksExecution_setInputFromMemory</a> and <a class="el" href="group___neural_networks.html#ga379a9efd313e22d7d8e1e1bef7c0defb">ANeuralNetworksExecution_setOutputFromMemory</a>. </p>

<p>Definition at line <a class="el" href="_neural_networks_8h_source.html#l01276">1276</a> of file <a class="el" href="_neural_networks_8h_source.html">NeuralNetworks.h</a>.</p>

</div>
</div>
<a class="anchor" id="ga4ce6f20a94d3a2de47fa5a810feeb9a4"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">typedef struct <a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> <a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>ANeuralNetworksModel is an opaque type that contains a description of the mathematical operations that constitute the model. </p>
<p>The model will be built by calling</p><ul>
<li>
<a class="el" href="group___neural_networks.html#ga8142daaf804adc33fea8e44af2ba2307">ANeuralNetworksModel_create</a>, </li>
<li>
<a class="el" href="group___neural_networks.html#ga5cf00af11c3bd21d27c0dff6ed7a15be">ANeuralNetworksModel_addOperation</a>, </li>
<li>
<a class="el" href="group___neural_networks.html#gab4bf35bfd0530a80c1cbd38294bc3007">ANeuralNetworksModel_addOperand</a>, </li>
</ul>
<p>A model is completed by calling <a class="el" href="group___neural_networks.html#ga2324b730b593482fda8f8f3a129ba06d">ANeuralNetworksModel_finish</a>. A model is destroyed by calling <a class="el" href="group___neural_networks.html#ga2287b1751678d75a349faa36956602fb">ANeuralNetworksModel_free</a>.</p>
<p>A model cannot be modified once <a class="el" href="group___neural_networks.html#ga2324b730b593482fda8f8f3a129ba06d">ANeuralNetworksModel_finish</a> has been called on it.</p>
<p>It is the application's responsibility to make sure that only one thread modifies a model at a given time. It is however safe for more than one thread to use the model once <a class="el" href="group___neural_networks.html#ga2324b730b593482fda8f8f3a129ba06d">ANeuralNetworksModel_finish</a> has returned.</p>
<p>It is also the application's responsibility to ensure that there are no other uses of the model after calling <a class="el" href="group___neural_networks.html#ga2287b1751678d75a349faa36956602fb">ANeuralNetworksModel_free</a>. This includes any compilation or execution object created using the model.</p>

<p>Definition at line <a class="el" href="_neural_networks_8h_source.html#l01302">1302</a> of file <a class="el" href="_neural_networks_8h_source.html">NeuralNetworks.h</a>.</p>

</div>
</div>
<a class="anchor" id="gaf2dc08c1084c170b255608f41d26297f"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">typedef struct <a class="el" href="struct_a_neural_networks_operand_type.html">ANeuralNetworksOperandType</a>  <a class="el" href="struct_a_neural_networks_operand_type.html">ANeuralNetworksOperandType</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p><a class="el" href="struct_a_neural_networks_operand_type.html" title="ANeuralNetworksOperandType describes the type of an operand. ">ANeuralNetworksOperandType</a> describes the type of an operand. </p>
<p>This structure is used to describe both scalars and tensors. </p>

</div>
</div>
<h2 class="groupheader">Enumeration Type Documentation</h2>
<a class="anchor" id="gadc29c2ff13d900c2f185ee95427fb06c"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">anonymous enum</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>For <a class="el" href="group___neural_networks.html#gab95e96267e0f955086b87a743dad44ca">ANeuralNetworksModel_setOperandValue</a>, values with a length smaller or equal to this will be immediately copied into the model. </p>
<p>The size is in bytes. </p>

<p>Definition at line <a class="el" href="_neural_networks_8h_source.html#l01254">1254</a> of file <a class="el" href="_neural_networks_8h_source.html">NeuralNetworks.h</a>.</p>

</div>
</div>
<a class="anchor" id="ga4ec620045a39909a6bf00b3ee0c4d414"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="group___neural_networks.html#ga4ec620045a39909a6bf00b3ee0c4d414">FuseCode</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Fused activation function types. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a class="anchor" id="gga4ec620045a39909a6bf00b3ee0c4d414a0f7344826e8abfa2ba90c82e856dc4f9"></a>ANEURALNETWORKS_FUSED_NONE&#160;</td><td class="fielddoc">
<p>NO fused activation function. </p>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="gga4ec620045a39909a6bf00b3ee0c4d414abfcb75d9fb70f78934766b830d98d7d6"></a>ANEURALNETWORKS_FUSED_RELU&#160;</td><td class="fielddoc">
<p>Fused ReLU activation function. </p>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="gga4ec620045a39909a6bf00b3ee0c4d414a9c969b9474ae51f8ecc544e11fbb8303"></a>ANEURALNETWORKS_FUSED_RELU1&#160;</td><td class="fielddoc">
<p>Fused ReLU1 activation function. </p>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="gga4ec620045a39909a6bf00b3ee0c4d414a29b9372bc4e003e080ef85342fd6c429"></a>ANEURALNETWORKS_FUSED_RELU6&#160;</td><td class="fielddoc">
<p>Fused ReLU6 activation function. </p>
</td></tr>
</table>

<p>Definition at line <a class="el" href="_neural_networks_8h_source.html#l01171">1171</a> of file <a class="el" href="_neural_networks_8h_source.html">NeuralNetworks.h</a>.</p>

</div>
</div>
<a class="anchor" id="gaf06d1affd33f3bc698d0c04eceb23298"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="group___neural_networks.html#gaf06d1affd33f3bc698d0c04eceb23298">OperandCode</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Operand types. </p>
<p>The type of operands that can be added to a model.</p>
<p>Although we define many types, most operators accept just a few types. Most used are <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a>, <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a>, and <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298acb165f692e9d189c820ceba84b3c21dc">ANEURALNETWORKS_INT32</a>. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a class="anchor" id="ggaf06d1affd33f3bc698d0c04eceb23298a6aa658f93a72ca7356d9433f772ef578"></a>ANEURALNETWORKS_FLOAT32&#160;</td><td class="fielddoc">
<p>The following entries are used to declare scalars. </p>
<p>A 32 bit floating point scalar value. </p>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaf06d1affd33f3bc698d0c04eceb23298acb165f692e9d189c820ceba84b3c21dc"></a>ANEURALNETWORKS_INT32&#160;</td><td class="fielddoc">
<p>A signed 32 bit integer scalar value. </p>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaf06d1affd33f3bc698d0c04eceb23298ad392906165c1e93c2a9719998d65223c"></a>ANEURALNETWORKS_UINT32&#160;</td><td class="fielddoc">
<p>An unsigned 32 bit integer scalar value. </p>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447"></a>ANEURALNETWORKS_TENSOR_FLOAT32&#160;</td><td class="fielddoc">
<p>The following entries are used to declare tensors. </p>
<p>A tensor of 32 bit floating point values. </p>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaf06d1affd33f3bc698d0c04eceb23298ac34965d8e76ac5acfddf5acd9e40f896"></a>ANEURALNETWORKS_TENSOR_INT32&#160;</td><td class="fielddoc">
<p>A tensor of 32 bit integer values. </p>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3"></a>ANEURALNETWORKS_TENSOR_QUANT8_ASYMM&#160;</td><td class="fielddoc">
<p>A tensor of 8 bit integers that represent real numbers. </p>
<p>Attached to this tensor are two numbers that can be used to convert the 8 bit integer to the real value and vice versa. These two numbers are:</p><ul>
<li>scale: a 32 bit non-negative floating point value.</li>
<li>zeroPoint: an 32 bit integer, in range [0, 255].</li>
</ul>
<p>The formula is: real_value = (integer_value - zeroPoint) * scale. </p>
</td></tr>
</table>

<p>Definition at line <a class="el" href="_neural_networks_8h_source.html#l00063">63</a> of file <a class="el" href="_neural_networks_8h_source.html">NeuralNetworks.h</a>.</p>

</div>
</div>
<a class="anchor" id="gaabbe492c60331b13038e39d4207940e0"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="group___neural_networks.html#gaabbe492c60331b13038e39d4207940e0">OperationCode</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Operation types. </p>
<p>The type of operations that can be added to a model. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0ad681988001e5f8ab73230a311f4ab034"></a>ANEURALNETWORKS_ADD&#160;</td><td class="fielddoc">
<p>Adds two tensors, element-wise. </p>
<p>Takes two input tensors of identical type and compatible dimensions. The output is the sum of both input tensors, optionally modified by an activation function.</p>
<p>Two dimensions are compatible when:</p><ol type="1">
<li>they are equal, or</li>
<li>one of them is 1</li>
</ol>
<p>The size of the output is the maximum size along each dimension of the input operands. It starts with the trailing dimensions, and works its way forward.</p>
<p>Example: </p><pre class="fragment">input1.dimension = {4, 1, 2}
input2.dimension = {5, 4, 3, 1}
output.dimension = {5, 4, 3, 2}
</pre><p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a></li>
</ul>
<p>Supported tensor rank: up to 4</p>
<p>Inputs:</p><ul>
<li>0: A tensor.</li>
<li>1: A tensor of the same type, and compatible dimensions as input0.</li>
<li>2: An INT32 value, and has to be one of the <a class="el" href="group___neural_networks.html#ga4ec620045a39909a6bf00b3ee0c4d414">FuseCode</a> values. Specifies the activation to invoke on the result of each addition.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The sum, a tensor of the same type as input0. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0a12e6b53aadbd3736c38f1a159adea788"></a>ANEURALNETWORKS_AVERAGE_POOL_2D&#160;</td><td class="fielddoc">
<p>Performs a 2-D average pooling operation. </p>
<p>The output dimensions are functions of the filter dimensions, stride, and padding.</p>
<p>The values in the output tensor are computed as: </p><pre class="fragment">output[batch, row, col, channel] =
    sum_{i, j}(input[batch, row + i, col + j, channel]) / sum(1)
</pre><p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a></li>
</ul>
<p>Supported tensor rank: 4, with "NHWC" (i.e., Num_samples, Height, Width, and Channels) data layout.</p>
<p>Both explicit padding and implicit padding are supported.</p>
<p>Inputs (explicit padding):</p><ul>
<li>0: A 4-D tensor, of shape [batches, height, width, depth], specifying the input.</li>
<li>1: An INT32 value, specifying the padding on the left, in the ‘width’ dimension.</li>
<li>2: An INT32 value, specifying the padding on the right,in the ‘width’ dimension.</li>
<li>3: An INT32 value, specifying the padding on the top, in the ‘height’ dimension.</li>
<li>4: An INT32 value, specifying the padding on the bottom, in the ‘height’ dimension.</li>
<li>5: An INT32 value, specifying the stride when walking through input in the ‘width’ dimension.</li>
<li>6: An INT32 value, specifying the stride when walking through input in the ‘height’ dimension.</li>
<li>7: An INT32 value, specifying the filter width.</li>
<li>8: An INT32 value, specifying the filter height.</li>
<li>9: An INT32 value, and has to be one of the <a class="el" href="group___neural_networks.html#ga4ec620045a39909a6bf00b3ee0c4d414">FuseCode</a> values. Specifies the activation to invoke on the result of each addition.</li>
</ul>
<p>Inputs (implicit padding):</p><ul>
<li>0: A 4-D tensor, of shape [batches, height, width, depth], specifying the input.</li>
<li>1: An INT32 value, specifying the implicit padding scheme, has to be one of the <a class="el" href="group___neural_networks.html#gab72e9e6263fd5b015bb7f41ec18ce220">PaddingCode</a> values.</li>
<li>2: An INT32 value, specifying the stride when walking through input in the ‘width’ dimension.</li>
<li>3: An INT32 value, specifying the stride when walking through input in the ‘height’ dimension.</li>
<li>4: An INT32 value, specifying the filter width.</li>
<li>5: An INT32 value, specifying the filter height.</li>
<li>6: An INT32 value, and has to be one of the <a class="el" href="group___neural_networks.html#ga4ec620045a39909a6bf00b3ee0c4d414">FuseCode</a> values. Specifies the activation to invoke on the result of each addition.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output 4-D tensor, of shape [batches, out_height, out_width, depth]. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0a44cbea825c4b224dd3ea757e9b1f65ed"></a>ANEURALNETWORKS_CONCATENATION&#160;</td><td class="fielddoc">
<p>Concatenates the input tensors along the given dimension. </p>
<p>The input tensors must have identical type and the same dimensions except the dimension along the concatenation axis.</p>
<p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a></li>
</ul>
<p>Supported tensor rank: up to 4</p>
<p>Inputs:</p><ul>
<li>0 ~ n-1: The list of n input tensors, of shape [D0, D1, ..., Daxis(i), ..., Dm]. For inputs of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a> type, all input tensors must have the same scale and zeroPoint.</li>
<li>n: An INT32 value, specifying the concatenation axis.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output, a tensor of the same type as the input tensors. The output shape is [D0, D1, ..., sum(Daxis(i)), ..., Dm]. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0a34a73b5eaf458b67db5eda71557d1d01"></a>ANEURALNETWORKS_CONV_2D&#160;</td><td class="fielddoc">
<p>Performs an 2-D convolution operation. </p>
<p>The CONV_2D op sweeps a 2-D filter that can mix channels together over a batch of images, applying the filter to each window of each image of the appropriate size.</p>
<p>The output dimensions are functions of the filter dimensions, stride, and padding.</p>
<p>The values in the output tensor are computed as: </p><pre class="fragment">output[batch, row, col, channel] =
    sum_{i, j} (
        input[batch, row + i, col + j, k] *
        filter[channel, row + i, col + j, k] +
        bias[channel]
    )
</pre><p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a></li>
</ul>
<p>Supported tensor rank: 4, with "NHWC" data layout.</p>
<p>Both explicit padding and implicit padding are supported.</p>
<p>Inputs (explicit padding):</p><ul>
<li>0: A 4-D tensor, of shape [batches, height, width, depth_in], specifying the input.</li>
<li>1: A 4-D tensor, of shape [depth_out, filter_height, filter_width, depth_in], specifying the filter.</li>
<li>2: A 1-D tensor, of shape [depth_out], specifying the bias. For input tensor of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a> type, the bias should also be of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a>. For input tensor of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a> type, the bias should be of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298ac34965d8e76ac5acfddf5acd9e40f896">ANEURALNETWORKS_TENSOR_INT32</a>, with zeroPoint of 0 and bias_scale == input_scale * filter_scale.</li>
<li>3: An INT32 value, specifying the padding on the left, in the ‘width’ dimension.</li>
<li>4: An INT32 value, specifying the padding on the right,in the ‘width’ dimension.</li>
<li>5: An INT32 value, specifying the padding on the top, in the ‘height’ dimension.</li>
<li>6: An INT32 value, specifying the padding on the bottom, in the ‘height’ dimension.</li>
<li>7: An INT32 value, specifying the stride when walking through input in the ‘width’ dimension.</li>
<li>8: An INT32 value, specifying the stride when walking through input in the ‘height’ dimension.</li>
<li>9: An INT32 value, and has to be one of the <a class="el" href="group___neural_networks.html#ga4ec620045a39909a6bf00b3ee0c4d414">FuseCode</a> values. Specifies the activation to invoke on the result of each addition.</li>
</ul>
<p>Inputs (implicit padding):</p><ul>
<li>0: A 4-D tensor, of shape [batches, height, width, depth_in], specifying the input.</li>
<li>1: A 4-D tensor, of shape [depth_out, filter_height, filter_width, depth_in], specifying the filter.</li>
<li>2: A 1-D tensor, of shape [depth_out], specifying the bias. For input tensor of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a> type, the bias should also be of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a>. For input tensor of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a> type, the bias should be of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298ac34965d8e76ac5acfddf5acd9e40f896">ANEURALNETWORKS_TENSOR_INT32</a>, with zeroPoint of 0 and bias_scale == input_scale * filter_scale.</li>
<li>3: An INT32 value, specifying the implicit padding scheme, has to be one of the <a class="el" href="group___neural_networks.html#gab72e9e6263fd5b015bb7f41ec18ce220">PaddingCode</a> values.</li>
<li>4: An INT32 value, specifying the stride when walking through input in the ‘width’ dimension.</li>
<li>5: An INT32 value, specifying the stride when walking through input in the ‘height’ dimension.</li>
<li>6: An INT32 value, and has to be one of the <a class="el" href="group___neural_networks.html#ga4ec620045a39909a6bf00b3ee0c4d414">FuseCode</a> values. Specifies the activation to invoke on the result of each addition.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output 4-D tensor, of shape [batches, out_height, out_width, depth_out]. For output tensor of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a> type, the following condition must be satisfied: output_scale &gt; input_scale * filter_scale. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0a2b49a44b7ebba243fad01556c1f0392e"></a>ANEURALNETWORKS_DEPTHWISE_CONV_2D&#160;</td><td class="fielddoc">
<p>Performs a depthwise 2-D convolution operation. </p>
<p>Given an input tensor of shape [batches, height, width, depth_in] and a filter tensor of shape [1, filter_height, filter_width, depth_out] containing depth_out convolutional filters of depth 1, DEPTHWISE_CONV applies a different filter to each input channel (expanding from 1 channel to channel_multiplier channels for each), then concatenates the results together.</p>
<p>The output has depth_out = depth_in * depth_multiplier channels. The output dimensions are functions of the filter dimensions, stride, and padding.</p>
<p>The values in the output tensor are computed as: </p><pre class="fragment">output[b, i, j, k * channel_multiplier + q] =
    sum_{di, dj} (
        input[b, strides[1] * i + di, strides[2] * j + dj, k] *
        filter[1, di, dj, k * channel_multiplier + q]
    )
</pre><p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a></li>
</ul>
<p>Supported tensor rank: 4, with "NHWC" data layout.</p>
<p>Both explicit padding and implicit padding are supported.</p>
<p>Inputs (explicit padding):</p><ul>
<li>0: A 4-D tensor, of shape [batches, height, width, depth_in], specifying the input.</li>
<li>1: A 4-D tensor, of shape [1, filter_height, filter_width, depth_out], specifying the filter.</li>
<li>2: A 1-D tensor, of shape [depth_out], specifying the bias. For input tensor of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a> type, the bias should also be of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a>. For input tensor of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a> type, the bias should be of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298ac34965d8e76ac5acfddf5acd9e40f896">ANEURALNETWORKS_TENSOR_INT32</a>, with zeroPoint of 0 and bias_scale == input_scale * filter_scale.</li>
<li>3: An INT32 value, specifying the padding on the left, in the ‘width’ dimension.</li>
<li>4: An INT32 value, specifying the padding on the right,in the ‘width’ dimension.</li>
<li>5: An INT32 value, specifying the padding on the top, in the ‘height’ dimension.</li>
<li>6: An INT32 value, specifying the padding on the bottom, in the ‘height’ dimension.</li>
<li>7: An INT32 value, specifying the stride when walking through input in the ‘width’ dimension.</li>
<li>8: An INT32 value, specifying the stride when walking through input in the ‘height’ dimension.</li>
<li>9: An INT32 value, specifying the depthwise multiplier.</li>
<li>10: An INT32 value, and has to be one of the <a class="el" href="group___neural_networks.html#ga4ec620045a39909a6bf00b3ee0c4d414">FuseCode</a> values. Specifies the activation to invoke on the result of each addition.</li>
</ul>
<p>Inputs (explicit padding):</p><ul>
<li>0: A 4-D tensor, of shape [batches, height, width, depth_in], specifying the input.</li>
<li>1: A 4-D tensor, of shape [1, filter_height, filter_width, depth_out], specifying the filter.</li>
<li>2: A 1-D tensor, of shape [depth_out], specifying the bias. For input tensor of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a> type, the bias should also be of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a>. For input tensor of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a> type, the bias should be of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298ac34965d8e76ac5acfddf5acd9e40f896">ANEURALNETWORKS_TENSOR_INT32</a>, with zeroPoint of 0 and bias_scale == input_scale * filter_scale.</li>
<li>3: An INT32 value, specifying the implicit padding scheme, has to be one of the <a class="el" href="group___neural_networks.html#gab72e9e6263fd5b015bb7f41ec18ce220">PaddingCode</a> values.</li>
<li>4: An INT32 value, specifying the stride when walking through input in the ‘width’ dimension.</li>
<li>5: An INT32 value, specifying the stride when walking through input in the ‘height’ dimension.</li>
<li>6: An INT32 value, specifying the depthwise multiplier.</li>
<li>7: An INT32 value, and has to be one of the <a class="el" href="group___neural_networks.html#ga4ec620045a39909a6bf00b3ee0c4d414">FuseCode</a> values. Specifies the activation to invoke on the result of each addition.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output 4-D tensor, of shape [batches, out_height, out_width, depth_out]. For output tensor of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a> type, the following condition must be satisfied: output_scale &gt; input_scale * filter_scale. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0a34253f8b844b4c143f0fa36be3ba3f7a"></a>ANEURALNETWORKS_DEPTH_TO_SPACE&#160;</td><td class="fielddoc">
<p>Rearranges data from depth into blocks of spatial data. </p>
<p>More specifically, this op outputs a copy of the input tensor where values from the depth dimension are moved in spatial blocks to the height and width dimensions. The value block_size indicates the input block size and how the data is moved.</p>
<p>Chunks of data of size block_size * block_size from depth are rearranged into non-overlapping blocks of size block_size x block_size.</p>
<p>The width of the output tensor is input_depth * block_size, whereas the height is input_height * block_size. The depth of the input tensor must be divisible by block_size * block_size</p>
<p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a></li>
</ul>
<p>Supported tensor rank: 4, with "NHWC" data layout.</p>
<p>Inputs:</p><ul>
<li>0: A 4-D tensor, of shape [batches, height, width, depth_in], specifying the input.</li>
<li>1: An INT32 value, specifying the block_size. block_size must be &gt;=1 and block_size * block_size must be a divisor of the input depth.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output 4-D tensor, of shape [batch, height*block_size, width*block_size, depth/(block_size*block_size)]. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0ad4c9300b061d9d14669bd5acdc7538e2"></a>ANEURALNETWORKS_DEQUANTIZE&#160;</td><td class="fielddoc">
<p>Dequantizes the input tensor. </p>
<p>The formula is: </p><pre class="fragment">output = (input - zeroPoint) * scale.
</pre><p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a></li>
</ul>
<p>Supported tensor rank: up to 4</p>
<p>Inputs:</p><ul>
<li>0: A tensor of type <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a>.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output tensor of same shape as input0, but with type <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a>. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0a8d2ada77adb74357fc0770405bca0e3c"></a>ANEURALNETWORKS_EMBEDDING_LOOKUP&#160;</td><td class="fielddoc">
<p>Looks up sub-tensors in the input tensor. </p>
<p>This operator takes for input a tensor of values (Values) and a one-dimensional tensor of selection indices (Lookups). The output tensor is the concatenation of sub-tensors of Values as selected by Lookups.</p>
<p>Think of Values as being sliced along its first dimension: The entries in Lookups select which slices are concatenated together to create the output tensor.</p>
<p>For example, if Values has shape of [40, 200, 300] and Lookups has shape of [3], we would expect all three values found in Lookups to be between 0 and 39. The resulting tensor will have shape of [3, 200, 300].</p>
<p>If a value in Lookups is out of bounds, the operation will fail and an error will be reported.</p>
<p>Inputs:</p><ul>
<li>0: Lookups. A 1-D tensor of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298ac34965d8e76ac5acfddf5acd9e40f896">ANEURALNETWORKS_TENSOR_INT32</a> type. The values are indices into the first dimension of Values.</li>
<li>1: Values. An n-D tensor, where n &gt;= 2, from which sub-tensors are extracted.</li>
</ul>
<p>Output:</p><ul>
<li>0: A n-D tensor with the same rank and shape as the Values tensor, except for the first dimension which has the same size as Lookups' only dimension. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0acdb4a57160153118dc6f87af0e4eccc5"></a>ANEURALNETWORKS_FLOOR&#160;</td><td class="fielddoc">
<p>Computes element-wise floor() on the input tensor. </p>
<p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
</ul>
<p>Supported tensor rank: up to 4</p>
<p>Inputs:</p><ul>
<li>0: A tensor.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output tensor, of the same type and dimensions as the input tensor. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0aaada7a3dbaf4676aba560c933ff610c5"></a>ANEURALNETWORKS_FULLY_CONNECTED&#160;</td><td class="fielddoc">
<p>Denotes a fully (densely) connected layer, which connects all elements in the input tensor with each element in the output tensor. </p>
<p>This layer implements the operation: </p><pre class="fragment">outputs = activation(inputs * weights’ + bias)
</pre><p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a></li>
</ul>
<p>Supported tensor rank: up to 4.</p>
<p>Inputs:</p><ul>
<li>0: A tensor, specifying the input. If rank is greater than 2, then it gets flattened to a 2-D <a class="el" href="struct_tensor.html">Tensor</a>. The 2-D <a class="el" href="struct_tensor.html">Tensor</a> is handled as if dimensions corresponded to shape [batch_size, input_size], where “batch_size” corresponds to the batching dimension, and “input_size” is the size of the input.</li>
<li>1: A 2-D tensor, specifying the weights, of shape [num_units, input_size], where "num_units" corresponds to the number of output nodes.</li>
<li>2: A 1-D tensor, of shape [num_units], specifying the bias. For input tensor of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a> type, the bias should also be of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a>. For input tensor of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a> type, the bias should be of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298ac34965d8e76ac5acfddf5acd9e40f896">ANEURALNETWORKS_TENSOR_INT32</a>, with zeroPoint of 0 and bias_scale == input_scale * filter_scale.</li>
<li>3: An INT32 value, and has to be one of the <a class="el" href="group___neural_networks.html#ga4ec620045a39909a6bf00b3ee0c4d414">FuseCode</a> values. Specifies the activation to invoke on the result of each addition.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output tensor, of shape [batch_size, num_units]. For output tensor of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a> type, the following condition must be satisfied: output_scale &gt; input_scale * filter_scale. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0aca92716c8c73c1f0fa7f0757916fee26"></a>ANEURALNETWORKS_HASHTABLE_LOOKUP&#160;</td><td class="fielddoc">
<p>Looks up sub-tensors in the input tensor using a key-value map. </p>
<p>This operator takes for input a tensor of values (Values), a one-dimensional tensor of selection values (Lookups) and a one-dimensional tensor that maps these values to Values indexes. The output tensor is the concatenation of sub-tensors of Values as selected by Lookups via Keys.</p>
<p>Think of Values as being sliced along its outer-most dimension. The output is a concatenation of selected slices, with one slice for each entry of Lookups. The slice selected is the one at the same index as the Maps entry that matches the value in Lookups.</p>
<p>For a hit, the corresponding sub-tensor of Values is included in the Output tensor. For a miss, the corresponding sub-tensor in Output will have zero values.</p>
<p>For example, if Values has shape of [40, 200, 300], Keys should have a shape of [40]. If Lookups tensor has shape of [3], we're concatenating three slices, so the resulting tensor will have the shape of [3, 200, 300]. If the first entry in Lookups has the value 123456, we'll look for that value in Keys tensor. If the sixth entry of Keys contains 123456, we'll select the sixth slice of Values. If no entry in Keys has 123456, a slice of zeroes will be concatenated.</p>
<p>Inputs:</p><ul>
<li>0: Lookups. A 1-D <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298ac34965d8e76ac5acfddf5acd9e40f896">ANEURALNETWORKS_TENSOR_INT32</a> tensor with shape [ k ].</li>
<li>1: Keys. A 1-D <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298ac34965d8e76ac5acfddf5acd9e40f896">ANEURALNETWORKS_TENSOR_INT32</a> tensor with shape [ n ]; Keys and Values pair represent a map, i.e., the ith element in Keys (Keys[i]) is the key to select the ith sub-tensor in Values (Values[i]), where 0 &lt;= i &lt;= n-1. Keys tensor <em>MUST</em> be sorted in ascending order.</li>
<li>2: Values. A tensor with shape of [ n, … ]; i.e., the first dimension must be n.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: Output. A tensor with shape [ k …].</li>
<li>1: Hits. A boolean tensor with shape [ k ] indicates whether the lookup hits (True) or not (False). Stored as <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a> with offset 0 and scale 1.0f. A non-zero byte represents True, a hit. A zero indicates otherwise. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0abf295dee59560ff29d435226ec4c24bd"></a>ANEURALNETWORKS_L2_NORMALIZATION&#160;</td><td class="fielddoc">
<p>Applies L2 normalization along the depth dimension. </p>
<p>The values in the output tensor are computed as: </p><pre class="fragment">output[batch, row, col, channel] =
    input[batch, row, col, channel] /
    sqrt(sum_{c} pow(input[batch, row, col, c], 2))
</pre><p>For input tensor with more dimensions, independently normalizes each 1-D slice along dimension dim.</p>
<p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
</ul>
<p>Supported tensor rank: 4, with "NHWC" data layout (i.e., Num_samples, Height, Width, and Channels).</p>
<p>Inputs:</p><ul>
<li>0: A 4-D tensor, of shape [batches, height, width, depth].</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output 4-D tensor, of shape [batches, out_height, out_width, depth]. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0a2fb636e30d8853f9fa1a395e30660e92"></a>ANEURALNETWORKS_L2_POOL_2D&#160;</td><td class="fielddoc">
<p>Performs an 2-D L2 pooling operation. </p>
<p>The output dimensions are functions of the filter dimensions, stride, and padding.</p>
<p>The values in the output tensor are computed as: </p><pre class="fragment">output[batch, row, col, channel] =
    sqrt(sum_{i, j} pow(input[batch, row + i, col + j, channel], 2) / sum(1))
</pre><p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
</ul>
<p>Supported tensor rank: 4, with "NHWC" data layout.</p>
<p>Both explicit padding and implicit padding are supported.</p>
<p>Inputs (explicit padding):</p><ul>
<li>0: A 4-D tensor, of shape [batches, height, width, depth], specifying the input.</li>
<li>1: An INT32 value, specifying the padding on the left, in the ‘width’ dimension.</li>
<li>2: An INT32 value, specifying the padding on the right,in the ‘width’ dimension.</li>
<li>3: An INT32 value, specifying the padding on the top, in the ‘height’ dimension.</li>
<li>4: An INT32 value, specifying the padding on the bottom, in the ‘height’ dimension.</li>
<li>5: An INT32 value, specifying the stride when walking through input in the ‘width’ dimension.</li>
<li>6: An INT32 value, specifying the stride when walking through input in the ‘height’ dimension.</li>
<li>7: An INT32 value, specifying the filter width.</li>
<li>8: An INT32 value, specifying the filter height.</li>
<li>9: An INT32 value, and has to be one of the <a class="el" href="group___neural_networks.html#ga4ec620045a39909a6bf00b3ee0c4d414">FuseCode</a> values. Specifies the activation to invoke on the result of each addition.</li>
</ul>
<p>Inputs (implicit padding):</p><ul>
<li>0: A 4-D tensor, of shape [batches, height, width, depth], specifying the input.</li>
<li>1: An INT32 value, specifying the implicit padding scheme, has to be one of the <a class="el" href="group___neural_networks.html#gab72e9e6263fd5b015bb7f41ec18ce220">PaddingCode</a> values.</li>
<li>2: An INT32 value, specifying the stride when walking through input in the ‘width’ dimension.</li>
<li>3: An INT32 value, specifying the stride when walking through input in the ‘height’ dimension.</li>
<li>4: An INT32 value, specifying the filter width.</li>
<li>5: An INT32 value, specifying the filter height.</li>
<li>6: An INT32 value, and has to be one of the <a class="el" href="group___neural_networks.html#ga4ec620045a39909a6bf00b3ee0c4d414">FuseCode</a> values. Specifies the activation to invoke on the result of each addition.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output 4-D tensor, of shape [batches, out_height, out_width, depth]. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0a876ccb0f3e6555637c5e278a7715fc05"></a>ANEURALNETWORKS_LOCAL_RESPONSE_NORMALIZATION&#160;</td><td class="fielddoc">
<p>Applies Local Response Normalization along the depth dimension. </p>
<p>The 4-D input tensor is treated as a 3-D array of 1-D vectors (along the last dimension), and each vector is normalized independently. Within a given vector, each component is divided by the weighted, squared sum of inputs within depth_radius.</p>
<p>The output is calculated using this formula: </p><pre class="fragment">sqr_sum[a, b, c, d] =
    sum(pow(input[a, b, c, d - depth_radius : d + depth_radius + 1], 2)
output = input / pow((bias + alpha * sqr_sum), beta)
</pre><p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
</ul>
<p>Supported tensor rank: 4, with "NHWC" data layout.</p>
<p>Inputs:</p><ul>
<li>0: A 4-D tensor, of shape [batches, height, width, depth], specifying the input.</li>
<li>1: An INT32 value, specifying the radius of the normalization window.</li>
<li>2: A FLOAT32 value, specifying the bias, must not be zero.</li>
<li>3: A FLOAT32 value, specifying the scale factor, alpha.</li>
<li>4: A FLOAT32 value, specifying the exponent, beta.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output tensor of same shape as input0. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0a82a340eb540933f638db420369650483"></a>ANEURALNETWORKS_LOGISTIC&#160;</td><td class="fielddoc">
<p>Computes sigmoid activation on the input tensor element-wise. </p>
<p>The output is calculated using this formula: </p><pre class="fragment">output = 1 / (1 + exp(-input))
</pre><p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a></li>
</ul>
<p>Supported tensor rank: up to 4.</p>
<p>Inputs:</p><ul>
<li>0: A tensor, specifying the input.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output tensor of same shape as input0. For <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a> type, the scale must be 1.f / 256 and the zeroPoint must be 0. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0a800cdcec5d7ba776789cb2d1ef669965"></a>ANEURALNETWORKS_LSH_PROJECTION&#160;</td><td class="fielddoc">
<p>Projects an input to a bit vector via locality senstive hashing. </p>
<p>Inputs:</p><ul>
<li>0: Hash functions. Dim.size == 2, DataType: Float. <a class="el" href="struct_tensor.html">Tensor</a>[0].Dim[0]: Number of hash functions. <a class="el" href="struct_tensor.html">Tensor</a>[0].Dim[1]: Number of seeds per hash functions. <a class="el" href="struct_tensor.html">Tensor</a>[0].Dim[1] &lt;= 32 in sparse case.</li>
<li>1: Input. Dim.size &gt;= 1, no restriction on DataType.</li>
<li>2: Weight. Optional. Dim.size == 1, DataType: Float. If not set, each input element is considered to have the same weight of 1.0. <a class="el" href="struct_tensor.html">Tensor</a>[1].Dim[0] == <a class="el" href="struct_tensor.html">Tensor</a>[2].Dim[0]</li>
<li><p class="startli">3: Type: Sparse: Value LSHProjectionType_SPARSE(=1). Computed bit vector is considered to be sparse. Each output element is an int32 made up of multiple bits computed from hash functions.</p>
<p class="startli">Dense: Value LSHProjectionType_DENSE(=2). Computed bit vector is considered to be dense. Each output element represents a bit and can take the value of either 0 or 1.</p>
</li>
</ul>
<p>Outputs:</p><ul>
<li>0: If the projection type is sparse: Output.Dim == { <a class="el" href="struct_tensor.html">Tensor</a>[0].Dim[0] } A tensor of int32 that represents hash signatures. If the projection type is Dense: Output.Dim == { <a class="el" href="struct_tensor.html">Tensor</a>[0].Dim[0] * <a class="el" href="struct_tensor.html">Tensor</a>[0].Dim[1] } A flattened tensor that represents projected bit vectors. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0ad0377e8c305e596fb7f64ff896671fc5"></a>ANEURALNETWORKS_LSTM&#160;</td><td class="fielddoc">
<p>Long short-term memory unit (LSTM) recurrent network layer. </p>
<p>The default non-peephole implementation is based on: <a href="http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf">http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf</a> S. Hochreiter and J. Schmidhuber. "Long Short-Term Memory". Neural Computation, 9(8):1735-1780, 1997.</p>
<p>The peephole implementation is based on: <a href="https://research.google.com/pubs/archive/43905.pdf">https://research.google.com/pubs/archive/43905.pdf</a> Hasim Sak, Andrew Senior, and Francoise Beaufays. "Long short-term memory
recurrent neural network architectures for large scale acoustic modeling." INTERSPEECH, 2014.</p>
<p>The coupling of input and forget gate (CIFG) is based on: <a href="http://arxiv.org/pdf/1503.04069.pdf">http://arxiv.org/pdf/1503.04069.pdf</a> Greff et al. "LSTM: A Search Space Odyssey"</p>
<p>The class has the following independently optional inputs:</p><ul>
<li>If input gate (if CIFG): “input_to_forget_weights”, “recurrent_to_input_weights”, “cell_to_input_weights”, “input_gate_bias”.</li>
<li>If no peephole connections: “cell_to_input_weights”, “cell_to_forget_weights”, “cell_to_output_weights”.</li>
<li>If no projection layer: “projection_weights” and “projection_bias”.</li>
<li>If no projection bias: “projection_bias”.</li>
</ul>
<p>Supported tensor types (type T):</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
</ul>
<p>Inputs:</p><ul>
<li>0: Input. A 2-D tensor of type T, of shape [batch_size, input_size], where “batch_size” corresponds to the batching dimension, and “input_size” is the size of the input.</li>
<li>1: input_to_input_weights. A 2-D tensor of type T, of shape [num_units, input_size], where “num_units” corresponds to the number of cell units.</li>
<li>2: input_to_forget_weights. A 2-D tensor of type T, of shape [num_units, input_size].</li>
<li>3: input_to_cell_weights. A 2-D tensor of type T, of shape [num_units, input_size].</li>
<li>4: input_to_output_weights. A 2-D tensor of type T, of shape [num_units, input_size].</li>
<li>5: recurrent_to_input_weights. A 2-D tensor of type T, of shape [num_units, output_size], where “output_size” corresponds to either the number of cell units (i.e., “num_units”), or the second dimension of the “projection_weights”, if defined.</li>
<li>6: recurrent_to_forget_weights. A 2-D tensor of type T, of shape [num_units, output_size].</li>
<li>7: recurrent_to_cell_weights. A 2-D tensor of type T, of shape [num_units, output_size].</li>
<li>8: recurrent_to_output_weights. A 2-D tensor of type T, of shape [num_units, output_size].</li>
<li>9: cell_to_input_weights. A 1-D tensor of type T, of shape [num_units].</li>
<li>10:cell_to_forget_weights. A 1-D tensor of type T, of shape [num_units].</li>
<li>11:cell_to_output_weights. A 1-D tensor of type T, of shape [num_units].</li>
<li>12:input_gate_bias. A 1-D tensor of type T, of shape [num_units].</li>
<li>13:forget_gate_bias. A 1-D tensor of type T, of shape [num_units].</li>
<li>14:cell_bias. A 1-D tensor of type T, of shape [num_units].</li>
<li>15:output_gate_bias. A 1-D tensor of type T, of shape [num_units].</li>
<li>16:projection_weights. A 2-D tensor of type T, of shape [output_size, num_units].</li>
<li>17:projection_bias. A 1-D tensor of type T, of shape [output_size].</li>
<li>18: output_state (in). A 2-D tensor of type T, of shape [batch_size, output_size].</li>
<li>19: cell_state (in). A 2-D tensor of type T, of shape [batch_size, num_units].</li>
<li>20:fused_activation_function. An optional <a class="el" href="group___neural_networks.html#ga4ec620045a39909a6bf00b3ee0c4d414">FuseCode</a> value indicating the activation function. If “NONE” is specified then it results in a linear activation.</li>
<li>21:cell_clip. A clipping threshold for the cell state, such that values are bound within [-cell_clip, cell_clip]. If set to 0.0 then clipping is disabled.</li>
<li>22:proj_clip. A clipping threshold for the output from the projection layer, such that values are bound within [-proj_clip, proj_clip]. If set to 0.0 then clipping is disabled.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: scratch_buffer. A 3-D tensor of type T, of shape [batch_size, num_cell, 4].</li>
<li>1: output_state (out). A 2-D tensor of type T, of shape [batch_size, output_size].</li>
<li>2: cell_state (out). A 2-D tensor of type T, of shape [batch_size, num_units].</li>
<li>3: output. A 2-D tensor of type T, of shape [batch_size, output_size]. This is effectively the same as the current “output_state” value. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0a0f227a4d98ad5af31f7fd4d255d246ce"></a>ANEURALNETWORKS_MAX_POOL_2D&#160;</td><td class="fielddoc">
<p>Performs an 2-D max pooling operation. </p>
<p>The output dimensions are functions of the filter dimensions, stride, and padding.</p>
<p>The values in the output tensor are computed as: </p><pre class="fragment">output[batch, row, col, channel] =
    max_{i, j} (input[batch, row + i, col + j, channel])
</pre><p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a></li>
</ul>
<p>Supported tensor rank: 4, with "NHWC" data layout.</p>
<p>Both explicit padding and implicit padding are supported.</p>
<p>Inputs (explicit padding):</p><ul>
<li>0: A 4-D tensor, of shape [batches, height, width, depth], specifying the input.</li>
<li>1: An INT32 value, specifying the padding on the left, in the ‘width’ dimension.</li>
<li>2: An INT32 value, specifying the padding on the right,in the ‘width’ dimension.</li>
<li>3: An INT32 value, specifying the padding on the top, in the ‘height’ dimension.</li>
<li>4: An INT32 value, specifying the padding on the bottom, in the ‘height’ dimension.</li>
<li>5: An INT32 value, specifying the stride when walking through input in the ‘width’ dimension.</li>
<li>6: An INT32 value, specifying the stride when walking through input in the ‘height’ dimension.</li>
<li>7: An INT32 value, specifying the filter width.</li>
<li>8: An INT32 value, specifying the filter height.</li>
<li>9: An INT32 value, and has to be one of the <a class="el" href="group___neural_networks.html#ga4ec620045a39909a6bf00b3ee0c4d414">FuseCode</a> values. Specifies the activation to invoke on the result of each addition.</li>
</ul>
<p>Inputs (implicit padding):</p><ul>
<li>0: A 4-D tensor, of shape [batches, height, width, depth], specifying the input.</li>
<li>1: An INT32 value, specifying the implicit padding scheme, has to be one of the <a class="el" href="group___neural_networks.html#gab72e9e6263fd5b015bb7f41ec18ce220">PaddingCode</a> values.</li>
<li>2: An INT32 value, specifying the stride when walking through input in the ‘width’ dimension.</li>
<li>3: An INT32 value, specifying the stride when walking through input in the ‘height’ dimension.</li>
<li>4: An INT32 value, specifying the filter width.</li>
<li>5: An INT32 value, specifying the filter height.</li>
<li>6: An INT32 value, and has to be one of the <a class="el" href="group___neural_networks.html#ga4ec620045a39909a6bf00b3ee0c4d414">FuseCode</a> values. Specifies the activation to invoke on the result of each addition.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output 4-D tensor, of shape [batches, out_height, out_width, depth]. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0ab34ca99890c827b536ce66256a803d7a"></a>ANEURALNETWORKS_MUL&#160;</td><td class="fielddoc">
<p>Multiplies two tensors, element-wise. </p>
<p>Takes two input tensors of identical type and compatible dimensions. The output is the product of both input tensors, optionally modified by an activation function.</p>
<p>Two dimensions are compatible when:</p><ol type="1">
<li>they are equal, or</li>
<li>one of them is 1</li>
</ol>
<p>The size of the resulting output is the maximum size along each dimension of the input operands. It starts with the trailing dimensions, and works its way forward.</p>
<p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a></li>
</ul>
<p>Supported tensor rank: up to 4</p>
<p>Inputs:</p><ul>
<li>0: A tensor.</li>
<li>1: A tensor of the same type, and compatible dimensions as input0.</li>
<li>2: An INT32 value, and has to be one of the <a class="el" href="group___neural_networks.html#ga4ec620045a39909a6bf00b3ee0c4d414">FuseCode</a> values. Specifies the activation to invoke on the result of each addition.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The product, a tensor of the same type as input0. For output tensor of <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a> type, the following condition must be satisfied: output_scale &gt; input1_scale * input2_scale. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0abb2f979866b131c5089ba0caaecee656"></a>ANEURALNETWORKS_RELU&#160;</td><td class="fielddoc">
<p>Computes rectified linear activation on the input tensor element-wise. </p>
<p>The output is calculated using this formula: </p><pre class="fragment">output = max(0, input)
</pre><p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a></li>
</ul>
<p>Supported tensor rank: up to 4.</p>
<p>Inputs:</p><ul>
<li>0: A tensor, specifying the input.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output tensor of same shape as input0. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0a73b9a2ded1dda2925d2e73aec44d2e2e"></a>ANEURALNETWORKS_RELU1&#160;</td><td class="fielddoc">
<p>Computes rectified linear 1 activation on the input tensor element-wise. </p>
<p>The output is calculated using this formula: </p><pre class="fragment">output = min(1.f, max(-1.f, input))
</pre><p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a></li>
</ul>
<p>Supported tensor rank: up to 4.</p>
<p>Inputs:</p><ul>
<li>0: A tensor, specifying the input.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output tensor of same shape as input0. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0a04a24c2d6f0aac4c3f5324c1d7764714"></a>ANEURALNETWORKS_RELU6&#160;</td><td class="fielddoc">
<p>Computes rectified linear 6 activation on the input tensor element-wise. </p>
<p>The output is calculated using this formula: </p><pre class="fragment">output = min(6, max(0, input))
</pre><p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a></li>
</ul>
<p>Supported tensor rank: up to 4.</p>
<p>Inputs:</p><ul>
<li>0: A tensor, specifying the input.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output tensor of same shape as input0. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0a535e7e99383ee49456c8671843b93a59"></a>ANEURALNETWORKS_RESHAPE&#160;</td><td class="fielddoc">
<p>Reshapes a tensor. </p>
<p>Given tensor, this operation returns a tensor that has the same values as tensor, but with a newly specified shape.</p>
<p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a></li>
</ul>
<p>Supported tensor rank: up to 4.</p>
<p>Inputs:</p><ul>
<li>0: A tensor, specifying the tensor to be reshaped.</li>
<li>1: A 1-D tensor of type <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298ac34965d8e76ac5acfddf5acd9e40f896">ANEURALNETWORKS_TENSOR_INT32</a>, defining the shape of the output tensor. The number of elements implied by shape must be the same as the number of elements in the input tensor.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output tensor, of shape specified by the input shape. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0a42bd92518e273b6716ecd56b571fcd3e"></a>ANEURALNETWORKS_RESIZE_BILINEAR&#160;</td><td class="fielddoc">
<p>Resizes images to given size using the bilinear interpretation. </p>
<p>Resized images will be distorted if their output aspect ratio is not the same as input aspect ratio.</p>
<p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
</ul>
<p>Supported tensor rank: 4, with "NHWC" data layout.</p>
<p>Inputs:</p><ul>
<li>0: A 4-D tensor, of shape [batches, height, width, depth], specifying the input.</li>
<li>1: An INT32 value, specifying the output height of the output tensor.</li>
<li>2: An INT32 value, specifying the output width of the output tensor.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output 4-D tensor, of shape [batches, new_height, new_width, depth]. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0acd2684ac9c73bb29767b534e78a332e8"></a>ANEURALNETWORKS_RNN&#160;</td><td class="fielddoc">
<p>A basic recurrent neural network layer. </p>
<p>This layer implements the operation: outputs = state = activation(inputs * input_weights + state * recurrent_weights + bias)</p>
<p>Where:</p><ul>
<li>“input_weights” is a weight matrix that multiplies the inputs;</li>
<li>“recurrent_weights” is a weight matrix that multiplies the current “state” which itself is the output from the previous time step computation;</li>
<li>“bias” is a bias vector (added to each output vector in the batch);</li>
<li>“activation” is the function passed as the “fused_activation_function” argument (if not “NONE”).</li>
</ul>
<p>Supported tensor types (Type T):</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
</ul>
<p>Inputs:</p><ul>
<li>0: input. A 2-D tensor of type T, of shape [batch_size, input_size], where “batch_size” corresponds to the batching dimension, and “input_size” is the size of the input.</li>
<li>1: weights. A 2-D tensor of type T, of shape [num_units, input_size], where “num_units” corresponds to the number of units.</li>
<li>2: recurrent_weights. A 2-D tensor of type T, of shape [num_units, num_units], with columns corresponding to the weights from each unit.</li>
<li>3: bias. A 1-D tensor of type T, of shape [num_units].</li>
<li>4: hidden state (in). A 2-D tensor of type T, of shape [batch_size, num_units].</li>
<li>5: fused_activation_function. An optional <a class="el" href="group___neural_networks.html#ga4ec620045a39909a6bf00b3ee0c4d414">FuseCode</a> value indicating the activation function. If “NONE” is specified then it results in a linear activation.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: hidden state (out). A 2-D tensor of type T, of shape [batch_size, num_units].</li>
<li>1: output. A 2-D tensor of type T, of shape [batch_size, num_units]. This is effectively the same as the current state value. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0a2bfbb83a537701e2843a3d5004250c2c"></a>ANEURALNETWORKS_SOFTMAX&#160;</td><td class="fielddoc">
<p>Computes the softmax activation on the input tensor element-wise, per batch, by normalizing the input vector so the maximum coefficient is zero. </p>
<p>The output is calculated using this formula: </p><pre class="fragment">output[batch, i] =
    exp((input[batch, i] - max(input[batch, :])) * beta) /
    sum_{k}{exp((input[batch, k] - max(input[batch, :])) * beta)}
</pre><p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a></li>
</ul>
<p>Supported tensor rank: 2 or 4.</p>
<p>Inputs:</p><ul>
<li>0: A 2-D or 4-D tensor, specifying the tensor to be reshaped.</li>
<li>1: A FLOAT32 value, specifying the positive scaling factor for the exponent, beta.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output tensor of same shape as input0. For <a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a> type, the scale must be 1.f / 256 and the zeroPoint must be 0. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0a90099ec472f6571a932b111d979dcccd"></a>ANEURALNETWORKS_SPACE_TO_DEPTH&#160;</td><td class="fielddoc">
<p>Rearranges blocks of spatial data, into depth. </p>
<p>More specifically, this op outputs a copy of the input tensor where values from the height and width dimensions are moved to the depth dimension. The value block_size indicates the input block size and how the data is moved.</p>
<p>Chunks of data of size block_size * block_size from depth are rearranged into non-overlapping blocks of size block_size x block_size.</p>
<p>The depth of the output tensor is input_depth * block_size * block_size. The input tensor's height and width must be divisible by block_size.</p>
<p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298a07984961d5c7c12f0f8c811bedd85dc3">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</a></li>
</ul>
<p>Supported tensor rank: 4, with "NHWC" data layout.</p>
<p>Inputs:</p><ul>
<li>0: A 4-D tensor, of shape [batches, height, width, depth_in], specifying the input.</li>
<li>1: An INT32 value, specifying the block_size. block_size must be &gt;=1 and block_size must be a divisor of both the input height and width.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output 4-D tensor, of shape [batch, height/block_size, width/block_size, depth*block_size*block_size]. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0a7096de21038c1ce49d354a00cba7b552"></a>ANEURALNETWORKS_SVDF&#160;</td><td class="fielddoc">
<p>SVDF op is a kind of stateful layer derived from the notion that a densely connected layer that's processing a sequence of input frames can be approximated by using a singular value decomposition of each of its nodes. </p>
<p>The implementation is based on:</p>
<p><a href="https://research.google.com/pubs/archive/43813.pdf">https://research.google.com/pubs/archive/43813.pdf</a></p>
<p>P. Nakkiran, R. Alvarez, R. Prabhavalkar, C. Parada. “Compressing Deep Neural Networks using a Rank-Constrained Topology”. INTERSPEECH, 2015.</p>
<p>It processes the incoming input using a 2-stage filtering mechanism:</p><ul>
<li>stage 1 performs filtering on the "features" dimension, whose outputs get pushed into a memory of fixed-size memory_size.</li>
<li>stage 2 performs filtering on the "time" dimension of the memory_size memoized outputs of stage 1.</li>
</ul>
<p>Specifically, for rank 1, this layer implements the operation:</p>
<p>memory = push(conv1d(inputs, weights_feature, feature_dim, "ANEURALNETWORKS_PADDING_VALID")); outputs = activation(memory * weights_time + bias);</p>
<p>Where:</p><ul>
<li>“weights_feature” is a weights matrix that processes the inputs (by convolving the input with every “feature filter”), and whose outputs get pushed, stacked in order, into the fixed-size “memory” (the oldest entry gets dropped);</li>
<li>“weights_time” is a weights matrix that processes the “memory” (by a batched matrix multiplication on the num_units);</li>
<li>“bias” is an optional bias vector (added to each output vector in the batch); and</li>
<li>“activation” is the function passed as the “fused_activation_function” argument (if not “NONE”).</li>
</ul>
<p>Each rank adds a dimension to the weights matrices by means of stacking the filters.</p>
<p>Supported tensor types (type T):</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
</ul>
<p>Inputs:</p><ul>
<li>0: input. A 2-D tensor of type T, of shape [batch_size, input_size], where “batch_size” corresponds to the batching dimension, and “input_size” is the size of the input.</li>
<li>1: weights_feature. A 2-D tensor of type T, of shape [num_units, input_size], where “num_units” corresponds to the number of units.</li>
<li>2: weights_time. A 2-D tensor of type T, of shape [num_units, memory_size], where “memory_size” corresponds to the fixed-size of the memory.</li>
<li>3: bias. An optional 1-D tensor of type T, of shape [num_units].</li>
<li>4: state (in). A 2-D tensor of type T, of shape [batch_size, (memory_size - 1) * num_units * rank].</li>
<li>5: rank. The rank of the SVD approximation.</li>
<li>6: fused_activation_function. An optional <a class="el" href="group___neural_networks.html#ga4ec620045a39909a6bf00b3ee0c4d414">FuseCode</a> value indicating the activation function. If “NONE” is specified then it results in a linear activation.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: state (out). A 2-D tensor of type T, of shape [batch_size, (memory_size - 1) * num_units * rank].</li>
<li>1: output. A 2-D tensor of type T, of shape [batch_size, num_units]. </li>
</ul>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggaabbe492c60331b13038e39d4207940e0a4b63c9caab823f112d82d853a77381e5"></a>ANEURALNETWORKS_TANH&#160;</td><td class="fielddoc">
<p>Computes hyperbolic tangent of input tensor element-wise. </p>
<p>The output is calculated using this formula: </p><pre class="fragment">output = tanh(input)
</pre><p>Supported tensor types:</p><ul>
<li><a class="el" href="group___neural_networks.html#ggaf06d1affd33f3bc698d0c04eceb23298aee4bc05d71c31e22e39e05470e965447">ANEURALNETWORKS_TENSOR_FLOAT32</a></li>
</ul>
<p>Supported tensor rank: up to 4.</p>
<p>Inputs:</p><ul>
<li>0: A tensor, specifying the input.</li>
</ul>
<p>Outputs:</p><ul>
<li>0: The output tensor of same shape as input0. </li>
</ul>
</td></tr>
</table>

<p>Definition at line <a class="el" href="_neural_networks_8h_source.html#l00097">97</a> of file <a class="el" href="_neural_networks_8h_source.html">NeuralNetworks.h</a>.</p>

</div>
</div>
<a class="anchor" id="gab72e9e6263fd5b015bb7f41ec18ce220"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="group___neural_networks.html#gab72e9e6263fd5b015bb7f41ec18ce220">PaddingCode</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Implicit padding algorithms. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a class="anchor" id="ggab72e9e6263fd5b015bb7f41ec18ce220af941cf111bcdf02b706e6290310ded19"></a>ANEURALNETWORKS_PADDING_SAME&#160;</td><td class="fielddoc">
<p>SAME padding. </p>
<p>Padding on both ends are the "same": padding_to_beginning = total_padding / 2 padding_to_end = (total_padding + 1)/2. i.e., for even number of padding, padding to both ends are exactly the same; for odd number of padding, padding to the ending is bigger than the padding to the beginning by 1.</p>
<p>total_padding is a function of input, stride and filter size. It could be computed as follows: out_size = (input + stride - 1) / stride; needed_input = (out_size - 1) * stride + filter_size total_padding = max(0, needed_input - output_size) The computation is the same for the horizontal and vertical directions. </p>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="ggab72e9e6263fd5b015bb7f41ec18ce220a0744f0fca811cc952ae983d689dbc4d8"></a>ANEURALNETWORKS_PADDING_VALID&#160;</td><td class="fielddoc">
<p>VALID padding. </p>
<p>No padding. When the input size is not evenly divisible by the filter size, the input at the end that could not fill the whole filter tile will simply be ignored. </p>
</td></tr>
</table>

<p>Definition at line <a class="el" href="_neural_networks_8h_source.html#l01186">1186</a> of file <a class="el" href="_neural_networks_8h_source.html">NeuralNetworks.h</a>.</p>

</div>
</div>
<a class="anchor" id="ga034380829226e2d980b2a7e63c992f18"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">enum <a class="el" href="group___neural_networks.html#ga034380829226e2d980b2a7e63c992f18">PreferenceCode</a></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Execution preferences. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a class="anchor" id="gga034380829226e2d980b2a7e63c992f18a370c42db64448662ad79116556bcec01"></a>ANEURALNETWORKS_PREFER_LOW_POWER&#160;</td><td class="fielddoc">
<p>Prefer executing in a way that minimizes battery drain. </p>
<p>This is desirable for compilations that will be executed often. </p>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="gga034380829226e2d980b2a7e63c992f18af7fff807061a3e9358364a502691d887"></a>ANEURALNETWORKS_PREFER_FAST_SINGLE_ANSWER&#160;</td><td class="fielddoc">
<p>Prefer returning a single answer as fast as possible, even if this causes more power consumption. </p>
</td></tr>
<tr><td class="fieldname"><a class="anchor" id="gga034380829226e2d980b2a7e63c992f18af727c25f1e2d8dcc693c477aef4ea5f5"></a>ANEURALNETWORKS_PREFER_SUSTAINED_SPEED&#160;</td><td class="fielddoc">
<p>Prefer maximizing the throughput of successive frames, for example when processing successive frames coming from the camera. </p>
</td></tr>
</table>

<p>Definition at line <a class="el" href="_neural_networks_8h_source.html#l01217">1217</a> of file <a class="el" href="_neural_networks_8h_source.html">NeuralNetworks.h</a>.</p>

</div>
</div>
<h2 class="groupheader">Function Documentation</h2>
<a class="anchor" id="ga10451d74cade530ceb163a2d6f7508f0"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ANeuralNetworksCompilation_create </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> *&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a> **&#160;</td>
          <td class="paramname"><em>compilation</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create a <a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a> to compile the given model. </p>
<p>This only creates the object. Compilation is only performed once <a class="el" href="group___neural_networks.html#gaa9fe0549c392bd3cfdbfc05182679864">ANeuralNetworksCompilation_finish</a> is invoked.</p>
<p><a class="el" href="group___neural_networks.html#gaa9fe0549c392bd3cfdbfc05182679864">ANeuralNetworksCompilation_finish</a> should be called once all desired properties have been set on the compilation.</p>
<p><a class="el" href="group___neural_networks.html#ga2287b1751678d75a349faa36956602fb">ANeuralNetworksModel_free</a> should be called once the compilation is no longer needed.</p>
<p>The provided model must outlive the compilation.</p>
<p>The model must already have been finished by a call to <a class="el" href="group___neural_networks.html#ga2324b730b593482fda8f8f3a129ba06d">ANeuralNetworksModel_finish</a>.</p>
<p>See <a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a> for information on multithreaded usage.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">model</td><td>The <a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> to be compiled. </td></tr>
    <tr><td class="paramname">compilation</td><td>The newly created object or NULL if unsuccessful.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>ANEURALNETWORKS_NO_ERROR if successful, ANEURALNETWORKS_BAD_DATA if the model is invalid. </dd></dl>

</div>
</div>
<a class="anchor" id="gaa9fe0549c392bd3cfdbfc05182679864"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ANeuralNetworksCompilation_finish </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a> *&#160;</td>
          <td class="paramname"><em>compilation</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Indicate that we have finished modifying a compilation. </p>
<p>Required before calling <a class="el" href="group___neural_networks.html#ga1079439ec94c91b9a0d60005d6bad576">ANeuralNetworksExecution_create</a>.</p>
<p>An application is responsible to make sure that no other thread uses the compilation at the same time.</p>
<p>This function must only be called once for a given compilation.</p>
<p>See <a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a> for information on multithreaded usage.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">compilation</td><td>The compilation to be finished.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>ANEURALNETWORKS_NO_ERROR if successful. </dd></dl>

</div>
</div>
<a class="anchor" id="gab62e33fbdc133bc6c4bde11fcaec2234"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void ANeuralNetworksCompilation_free </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a> *&#160;</td>
          <td class="paramname"><em>compilation</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Destroy a compilation. </p>
<p>The compilation need not have been finished by a call to <a class="el" href="group___neural_networks.html#ga2324b730b593482fda8f8f3a129ba06d">ANeuralNetworksModel_finish</a>.</p>
<p>See <a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a> for information on multithreaded usage.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">compilation</td><td>The compilation to be destroyed. Passing NULL is acceptable and results in no operation. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ga538ce3c0113ed3b54af97cf491815df3"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ANeuralNetworksCompilation_setPreference </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a> *&#160;</td>
          <td class="paramname"><em>compilation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>preference</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Sets the execution preference. </p>
<p>Provides guidance to the runtime when trade-offs are possible.</p>
<p>See <a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a> for information on multithreaded usage.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">compilation</td><td>The compilation to be modified. </td></tr>
    <tr><td class="paramname">preference</td><td>Either <a class="el" href="">PREFER_LOW_POWER</a>, <a class="el" href="">PREFER_SINGLE_FAST_ANSWER</a>, or <a class="el" href="">PREFER_SUSTAINED_SPEED</a>.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>ANEURALNETWORKS_NO_ERROR if successful. </dd></dl>

</div>
</div>
<a class="anchor" id="gab0f751c3202a28515371d447c43d97aa"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void ANeuralNetworksEvent_free </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#ga8b595e8510f91fa0f7d9eaa09fe6c269">ANeuralNetworksEvent</a> *&#160;</td>
          <td class="paramname"><em>event</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Destroys the event. </p>
<p>See <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> for information on multithreaded usage. </p>

</div>
</div>
<a class="anchor" id="gab6569a95097d55d2bd04e789faca1a78"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ANeuralNetworksEvent_wait </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#ga8b595e8510f91fa0f7d9eaa09fe6c269">ANeuralNetworksEvent</a> *&#160;</td>
          <td class="paramname"><em>event</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Waits until the execution completes. </p>
<p>More than one thread can wait on an event. When the execution completes, all threads will be released.</p>
<p>See <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> for information on multithreaded usage.</p>
<dl class="section return"><dt>Returns</dt><dd>ANEURALNETWORKS_NO_ERROR if the execution completed normally. </dd></dl>

</div>
</div>
<a class="anchor" id="ga1079439ec94c91b9a0d60005d6bad576"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ANeuralNetworksExecution_create </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a> *&#160;</td>
          <td class="paramname"><em>compilation</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> **&#160;</td>
          <td class="paramname"><em>execution</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create a <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> to apply the given compilation. </p>
<p>This only creates the object. Computation is only performed once <a class="el" href="group___neural_networks.html#ga54c60b23afdfff211fc30ef746a2d9e6">ANeuralNetworksExecution_startCompute</a> is invoked.</p>
<p>The provided compilation must outlive the execution.</p>
<p>See <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> for information on multithreaded usage.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">compilation</td><td>The <a class="el" href="group___neural_networks.html#gaaea7d6481c0077bf9547fdb887b55fe6">ANeuralNetworksCompilation</a> to be evaluated. </td></tr>
    <tr><td class="paramname">execution</td><td>The newly created object or NULL if unsuccessful.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>ANEURALNETWORKS_NO_ERROR if successful, ANEURALNETWORKS_BAD_DATA if the compilation is invalid. </dd></dl>

</div>
</div>
<a class="anchor" id="ga4472907d12644156ec45935be26c0852"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void ANeuralNetworksExecution_free </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> *&#160;</td>
          <td class="paramname"><em>execution</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Destroy an execution. </p>
<p>If called on an execution for which <a class="el" href="group___neural_networks.html#ga54c60b23afdfff211fc30ef746a2d9e6">ANeuralNetworksExecution_startCompute</a> has been called, the function will return immediately but will mark the execution to be deleted once the computation completes. The related <a class="el" href="group___neural_networks.html#ga8b595e8510f91fa0f7d9eaa09fe6c269">ANeuralNetworksEvent</a> will be signaled and the <a class="el" href="group___neural_networks.html#gab6569a95097d55d2bd04e789faca1a78">ANeuralNetworksEvent_wait</a> will return ANEURALNETWORKS_ERROR_DELETED.</p>
<p>See <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> for information on multithreaded usage.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">execution</td><td>The execution to be destroyed. Passing NULL is acceptable and results in no operation. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="gaf5540f8785a31b550ba7e7a78eed6a85"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ANeuralNetworksExecution_setInput </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> *&#160;</td>
          <td class="paramname"><em>execution</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>index</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="struct_a_neural_networks_operand_type.html">ANeuralNetworksOperandType</a> *&#160;</td>
          <td class="paramname"><em>type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>buffer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>length</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Associate a user buffer with an input of the model of the <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a>. </p>
<p>The provided buffer must outlive the execution.</p>
<p>If the input is optional, you can indicate that it is omitted by passing nullptr for buffer and 0 for length.</p>
<p>See <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> for information on multithreaded usage.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">execution</td><td>The execution to be modified. </td></tr>
    <tr><td class="paramname">index</td><td>The index of the input argument we are setting. It is an index into the lists passed to <a class="el" href="group___neural_networks.html#ga9bb7cd668b49da24e0c70ee6bf237a40">ANeuralNetworksModel_identifyInputsAndOutputs</a>. It is not the index associated with <a class="el" href="group___neural_networks.html#gab4bf35bfd0530a80c1cbd38294bc3007">ANeuralNetworksModel_addOperand</a>. </td></tr>
    <tr><td class="paramname">type</td><td>The type of the operand. This should be used to specify the dimensions that were set to 0 when the operand was added to the model. All other properties of the type must be the same as specified in the model. If the type is the same as specified when the model was built, NULL can be passed. </td></tr>
    <tr><td class="paramname">buffer</td><td>The buffer containing the data. </td></tr>
    <tr><td class="paramname">length</td><td>The length in bytes of the buffer.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>ANEURALNETWORKS_NO_ERROR if successful, ANEURALNETWORKS_BAD_DATA if the name is not recognized or the buffer is too small for the input. </dd></dl>

</div>
</div>
<a class="anchor" id="gaa8a30670b12f540765f00b1b6d3be011"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ANeuralNetworksExecution_setInputFromMemory </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> *&#160;</td>
          <td class="paramname"><em>execution</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>index</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="struct_a_neural_networks_operand_type.html">ANeuralNetworksOperandType</a> *&#160;</td>
          <td class="paramname"><em>type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group___neural_networks.html#ga9a6b7719f0613ba9e2c93cffd97ebfc0">ANeuralNetworksMemory</a> *&#160;</td>
          <td class="paramname"><em>memory</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>length</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Associate part of a memory object with an input of the model of the <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a>. </p>
<p>The provided memory must outlive the execution.</p>
<p>If the input is optional, you can indicate that it is omitted by usingLink ANeuralNetworks_setInput} instead, passing nullptr for buffer and 0 for length.</p>
<p>See <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> for information on multithreaded usage.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">execution</td><td>The execution to be modified. </td></tr>
    <tr><td class="paramname">index</td><td>The index of the input argument we are setting. It is an index into the lists passed to <a class="el" href="group___neural_networks.html#ga9bb7cd668b49da24e0c70ee6bf237a40">ANeuralNetworksModel_identifyInputsAndOutputs</a>. It is not the index associated with <a class="el" href="group___neural_networks.html#gab4bf35bfd0530a80c1cbd38294bc3007">ANeuralNetworksModel_addOperand</a>. </td></tr>
    <tr><td class="paramname">type</td><td>The type of the operand. This can be used to specify the dimensions that were set to 0 when the operand was added to the model. All other values must be the same as specified in the model. If the type is the same as specified when the model was built, NULL can be passed. </td></tr>
    <tr><td class="paramname">memory</td><td>The memory containing the data. </td></tr>
    <tr><td class="paramname">offset</td><td>This specifies the location of the data whithin the memory. The offset is in bytes from the start of memory. </td></tr>
    <tr><td class="paramname">length</td><td>The size in bytes of the data value.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>ANEURALNETWORKS_NO_ERROR if successful, ANEURALNETWORKS_BAD_DATA if the name is not recognized or the buffer is too small for the input. </dd></dl>

</div>
</div>
<a class="anchor" id="ga16ce3c18aa2574df91f7b7932bfdf48d"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ANeuralNetworksExecution_setOutput </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> *&#160;</td>
          <td class="paramname"><em>execution</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>index</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="struct_a_neural_networks_operand_type.html">ANeuralNetworksOperandType</a> *&#160;</td>
          <td class="paramname"><em>type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">void *&#160;</td>
          <td class="paramname"><em>buffer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>length</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Associate a user buffer with an output of the model of the <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a>. </p>
<p>If the output is optional, you can indicate that it is omitted by passing nullptr for buffer and 0 for length.</p>
<p>The provided buffer must outlive the execution.</p>
<p>See <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> for information on multithreaded usage.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">execution</td><td>The execution to be modified. </td></tr>
    <tr><td class="paramname">index</td><td>The index of the output argument we are setting. It is an index into the lists passed to <a class="el" href="group___neural_networks.html#ga9bb7cd668b49da24e0c70ee6bf237a40">ANeuralNetworksModel_identifyInputsAndOutputs</a>. It is not the index associated with <a class="el" href="group___neural_networks.html#gab4bf35bfd0530a80c1cbd38294bc3007">ANeuralNetworksModel_addOperand</a>. </td></tr>
    <tr><td class="paramname">type</td><td>The type of the operand. This can be used to specify the dimensions that were set to 0 when the operand was added to the model. All other values must be the same as specified in the model. If the type is the same as specified when the model was built, NULL can be passed. </td></tr>
    <tr><td class="paramname">buffer</td><td>The buffer where the data is to be written. </td></tr>
    <tr><td class="paramname">length</td><td>The length in bytes of the buffer.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>ANEURALNETWORKS_NO_ERROR if successful, ANEURALNETWORKS_BAD_DATA if the name is not recognized or the buffer is too small for the output. </dd></dl>

</div>
</div>
<a class="anchor" id="ga379a9efd313e22d7d8e1e1bef7c0defb"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ANeuralNetworksExecution_setOutputFromMemory </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> *&#160;</td>
          <td class="paramname"><em>execution</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>index</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="struct_a_neural_networks_operand_type.html">ANeuralNetworksOperandType</a> *&#160;</td>
          <td class="paramname"><em>type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group___neural_networks.html#ga9a6b7719f0613ba9e2c93cffd97ebfc0">ANeuralNetworksMemory</a> *&#160;</td>
          <td class="paramname"><em>memory</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>length</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Associate part of a memory object with an output of the model of the <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a>. </p>
<p>If the output is optional, you can indicate that it is omitted by usingLink ANeuralNetworks_setOutput} instead, passing nullptr for buffer and 0 for length.</p>
<p>The provided memory must outlive the execution.</p>
<p>See <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> for information on multithreaded usage.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">execution</td><td>The execution to be modified. </td></tr>
    <tr><td class="paramname">index</td><td>The index of the output argument we are setting. It is an index into the lists passed to <a class="el" href="group___neural_networks.html#ga9bb7cd668b49da24e0c70ee6bf237a40">ANeuralNetworksModel_identifyInputsAndOutputs</a>. It is not the index associated with <a class="el" href="group___neural_networks.html#gab4bf35bfd0530a80c1cbd38294bc3007">ANeuralNetworksModel_addOperand</a>. </td></tr>
    <tr><td class="paramname">type</td><td>The type of the operand. This can be used to specify the dimensions that were set to 0 when the operand was added to the model. All other values must be the same as specified in the model. If the type is the same as specified when the model was built, NULL can be passed. </td></tr>
    <tr><td class="paramname">memory</td><td>The memory where the data is to be stored. </td></tr>
    <tr><td class="paramname">offset</td><td>This specifies the location of the data whithin the memory. The offset is in bytes from the start of memory. </td></tr>
    <tr><td class="paramname">length</td><td>The length in bytes of the data value.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>ANEURALNETWORKS_NO_ERROR if successful, ANEURALNETWORKS_BAD_DATA if the name is not recognized or the buffer is too small for the output. </dd></dl>

</div>
</div>
<a class="anchor" id="ga54c60b23afdfff211fc30ef746a2d9e6"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ANeuralNetworksExecution_startCompute </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> *&#160;</td>
          <td class="paramname"><em>execution</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#ga8b595e8510f91fa0f7d9eaa09fe6c269">ANeuralNetworksEvent</a> **&#160;</td>
          <td class="paramname"><em>event</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Schedule evaluation of the execution. </p>
<p>Schedules evaluation of the execution. Once the model has been applied and the outputs are ready to be consumed, the returned event will be signaled. Use <a class="el" href="group___neural_networks.html#gab6569a95097d55d2bd04e789faca1a78">ANeuralNetworksEvent_wait</a> to wait for that event. </p>
<p>Multiple executions can be scheduled and evaluated concurrently. The runtime makes no guarantee on the ordering of completion of executions. If it's important to the application, the application should enforce the ordering by using <a class="el" href="group___neural_networks.html#gab6569a95097d55d2bd04e789faca1a78">ANeuralNetworksEvent_wait</a>.</p>
<p>ANeuralNetworksEvent_wait must be called to recuperate the resources used by the execution.</p>
<p>See <a class="el" href="group___neural_networks.html#gace4c4f3201c32eba9d18850e86dea33b">ANeuralNetworksExecution</a> for information on multithreaded usage.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">execution</td><td>The execution to be scheduled and executed. </td></tr>
    <tr><td class="paramname">event</td><td>The event that will be signaled on completion. event is set to NULL if there's an error.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>ANEURALNETWORKS_NO_ERROR if successful. </dd></dl>

</div>
</div>
<a class="anchor" id="ga3510b07da0ab9626fb84688fb91112be"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ANeuralNetworksMemory_createFromFd </td>
          <td>(</td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>protect</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>fd</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#ga9a6b7719f0613ba9e2c93cffd97ebfc0">ANeuralNetworksMemory</a> **&#160;</td>
          <td class="paramname"><em>memory</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Creates a shared memory object from a file descriptor. </p>
<p>The shared memory is backed by a file descriptor via mmap. See <a class="el" href="group___neural_networks.html#ga9a6b7719f0613ba9e2c93cffd97ebfc0">ANeuralNetworksMemory</a> for a description on how to use this shared memory.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">size</td><td>The requested size in bytes. Must not be larger than the file size. </td></tr>
    <tr><td class="paramname">prot</td><td>The desired memory protection for the mapping. It is either PROT_NONE or the bitwise OR of one or more of the following flags: PROT_READ, PROT_WRITE. </td></tr>
    <tr><td class="paramname">fd</td><td>The requested file descriptor. The file descriptor has to be mmap-able. The file descriptor will be duplicated. </td></tr>
    <tr><td class="paramname">offset</td><td>The offset to the beginning of the file of the area to map. The offset has to be aligned to a page size. </td></tr>
    <tr><td class="paramname">memory</td><td>The memory object to be created. Set to NULL if unsuccessful.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>ANEURALNETWORKS_NO_ERROR if the request completed normally. </dd></dl>

</div>
</div>
<a class="anchor" id="ga5ec77f5e69b20fac270eaeae2f8e0cb8"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void ANeuralNetworksMemory_free </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#ga9a6b7719f0613ba9e2c93cffd97ebfc0">ANeuralNetworksMemory</a> *&#160;</td>
          <td class="paramname"><em>memory</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Delete a memory object. </p>
<p>Destroys the object used by the run time to keep track of the memory. This will free the underlying actual memory if no other code has open handles to this memory.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">memory</td><td>The memory object to be freed. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="gab4bf35bfd0530a80c1cbd38294bc3007"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ANeuralNetworksModel_addOperand </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> *&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="struct_a_neural_networks_operand_type.html">ANeuralNetworksOperandType</a> *&#160;</td>
          <td class="paramname"><em>type</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Add an operand to a model. </p>
<p>The order in which the operands are added is important. The first one added to a model will have the index value 0, the second 1, etc. These indexes are used as operand identifiers in <a class="el" href="group___neural_networks.html#ga5cf00af11c3bd21d27c0dff6ed7a15be">ANeuralNetworksModel_addOperation</a>, <a class="el" href="group___neural_networks.html#gaf5540f8785a31b550ba7e7a78eed6a85">ANeuralNetworksExecution_setInput</a>, <a class="el" href="group___neural_networks.html#gaa8a30670b12f540765f00b1b6d3be011">ANeuralNetworksExecution_setInputFromMemory</a>, <a class="el" href="group___neural_networks.html#ga16ce3c18aa2574df91f7b7932bfdf48d">ANeuralNetworksExecution_setOutput</a>, <a class="el" href="group___neural_networks.html#ga379a9efd313e22d7d8e1e1bef7c0defb">ANeuralNetworksExecution_setOutputFromMemory</a> and <a class="el" href="">ANeuralNetworksExecution_setOperandValue</a>.</p>
<p>To build a model that can accomodate inputs of various sizes, as you may want to do for a CNN, set the size of the dimensions that will vary at run time to 0. If you do so, provide the full dimensions when calling <a class="el" href="group___neural_networks.html#gaf5540f8785a31b550ba7e7a78eed6a85">ANeuralNetworksExecution_setInput</a> or <a class="el" href="group___neural_networks.html#gaa8a30670b12f540765f00b1b6d3be011">ANeuralNetworksExecution_setInputFromMemory</a>.</p>
<p>Attempting to modify a model once <a class="el" href="group___neural_networks.html#ga2324b730b593482fda8f8f3a129ba06d">ANeuralNetworksModel_finish</a> has been called will return an error.</p>
<p>See <a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> for information on multithreaded usage.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">model</td><td>The model to be modified. </td></tr>
    <tr><td class="paramname">type</td><td>The <a class="el" href="struct_a_neural_networks_operand_type.html">ANeuralNetworksOperandType</a> that describes the shape of the operand.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>ANEURALNETWORKS_NO_ERROR if successful. </dd></dl>

</div>
</div>
<a class="anchor" id="ga5cf00af11c3bd21d27c0dff6ed7a15be"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ANeuralNetworksModel_addOperation </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> *&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ANeuralNetworksOperationType&#160;</td>
          <td class="paramname"><em>type</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>inputCount</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint32_t *&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>outputCount</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint32_t *&#160;</td>
          <td class="paramname"><em>outputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Add an operation to a model. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">model</td><td>The model to be modified. </td></tr>
    <tr><td class="paramname">type</td><td>The type of the operation. </td></tr>
    <tr><td class="paramname">inputCount</td><td>The number of entries in the inputs array. </td></tr>
    <tr><td class="paramname">inputs</td><td>An array of indexes identifying each operand. </td></tr>
    <tr><td class="paramname">outputCount</td><td>The number of entries in the outputs array. </td></tr>
    <tr><td class="paramname">outputs</td><td>An array of indexes identifying each operand.</td></tr>
  </table>
  </dd>
</dl>
<p>The operands specified by inputs and outputs must have been previously added by calls to <a class="el" href="group___neural_networks.html#gab4bf35bfd0530a80c1cbd38294bc3007">ANeuralNetworksModel_addOperand</a>.</p>
<p>Attempting to modify a model once <a class="el" href="group___neural_networks.html#ga2324b730b593482fda8f8f3a129ba06d">ANeuralNetworksModel_finish</a> has been called will return an error.</p>
<p>See <a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> for information on multithreaded usage.</p>
<dl class="section return"><dt>Returns</dt><dd>ANEURALNETWORKS_NO_ERROR if successful. </dd></dl>

</div>
</div>
<a class="anchor" id="ga8142daaf804adc33fea8e44af2ba2307"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ANeuralNetworksModel_create </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> **&#160;</td>
          <td class="paramname"><em>model</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create an empty <a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a>. </p>
<p>This only creates the object. Computation is performed once <a class="el" href="group___neural_networks.html#ga54c60b23afdfff211fc30ef746a2d9e6">ANeuralNetworksExecution_startCompute</a> is invoked.</p>
<p>The model should be constructed with calls to <a class="el" href="group___neural_networks.html#ga5cf00af11c3bd21d27c0dff6ed7a15be">ANeuralNetworksModel_addOperation</a> and <a class="el" href="group___neural_networks.html#gab4bf35bfd0530a80c1cbd38294bc3007">ANeuralNetworksModel_addOperand</a></p>
<p><a class="el" href="group___neural_networks.html#ga2324b730b593482fda8f8f3a129ba06d">ANeuralNetworksModel_finish</a> should be called once the model has been fully constructed.</p>
<p><a class="el" href="group___neural_networks.html#ga2287b1751678d75a349faa36956602fb">ANeuralNetworksModel_free</a> should be called once the model is no longer needed.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">model</td><td>The <a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> to be created. Set to NULL if unsuccessful.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>ANEURALNETWORKS_NO_ERROR if successful. </dd></dl>

</div>
</div>
<a class="anchor" id="ga2324b730b593482fda8f8f3a129ba06d"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ANeuralNetworksModel_finish </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> *&#160;</td>
          <td class="paramname"><em>model</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Indicate that we have finished modifying a model. </p>
<p>Required before calling <a class="el" href="group___neural_networks.html#ga10451d74cade530ceb163a2d6f7508f0">ANeuralNetworksCompilation_create</a>.</p>
<p>An application is responsible to make sure that no other thread uses the model at the same time.</p>
<p>This function must only be called once for a given model.</p>
<p>See <a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> for information on multithreaded usage.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">model</td><td>The model to be finished.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>ANEURALNETWORKS_NO_ERROR if successful. </dd></dl>

</div>
</div>
<a class="anchor" id="ga2287b1751678d75a349faa36956602fb"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void ANeuralNetworksModel_free </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> *&#160;</td>
          <td class="paramname"><em>model</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Destroy a model. </p>
<p>The model need not have been finished by a call to <a class="el" href="group___neural_networks.html#ga2324b730b593482fda8f8f3a129ba06d">ANeuralNetworksModel_finish</a>.</p>
<p>See <a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> for information on multithreaded usage.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">model</td><td>The model to be destroyed. Passing NULL is acceptable and results in no operation. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a class="anchor" id="ga9bb7cd668b49da24e0c70ee6bf237a40"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ANeuralNetworksModel_identifyInputsAndOutputs </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> *&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>inputCount</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint32_t *&#160;</td>
          <td class="paramname"><em>inputs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>outputCount</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint32_t *&#160;</td>
          <td class="paramname"><em>outputs</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Specfifies which operands will be the model's inputs and outputs. </p>
<p>An operand cannot be used for both input and output. Doing so will return an error.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">model</td><td>The model to be modified. </td></tr>
    <tr><td class="paramname">inputCount</td><td>The number of entries in the inputs array. </td></tr>
    <tr><td class="paramname">inputs</td><td>An array of indexes identifying the input operands. </td></tr>
    <tr><td class="paramname">outputCount</td><td>The number of entries in the outputs array. </td></tr>
    <tr><td class="paramname">outputs</td><td>An array of indexes identifying the output operands.</td></tr>
  </table>
  </dd>
</dl>
<p>The operands specified by inputs and outputs must have been previously added by calls to <a class="el" href="group___neural_networks.html#gab4bf35bfd0530a80c1cbd38294bc3007">ANeuralNetworksModel_addOperand</a>.</p>
<p>Attempting to modify a model once <a class="el" href="group___neural_networks.html#ga2324b730b593482fda8f8f3a129ba06d">ANeuralNetworksModel_finish</a> has been called will return an error.</p>
<p>See <a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> for information on multithreaded usage. </p>

</div>
</div>
<a class="anchor" id="gab95e96267e0f955086b87a743dad44ca"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ANeuralNetworksModel_setOperandValue </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> *&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>index</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const void *&#160;</td>
          <td class="paramname"><em>buffer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>length</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Sets an operand to a constant value. </p>
<p>Values of length smaller or equal to <a class="el" href="">ANEURALNETWORKS_MAX_SIZE_OF_IMMEDIATELY_COPIED_VALUES</a> are immediately copied into the model.</p>
<p>For values of length greater than <a class="el" href="">ANEURALNETWORKS_MAX_SIZE_OF_IMMEDIATELY_COPIED_VALUES</a>, a pointer to the buffer is stored within the model. The application is responsible for not changing the content of this region until all executions using this model have completed. As the data may be copied during processing, modifying the data after this call yields undefined results.</p>
<p>For large tensors, using <a class="el" href="group___neural_networks.html#gadd7a4261e062051516fd49c7217c20b8">ANeuralNetworksModel_setOperandValueFromMemory</a> is likely to be more efficient.</p>
<p>To indicate that an optional operand should be considered missing, pass nullptr for buffer and 0 for length.</p>
<p>Attempting to modify a model once <a class="el" href="group___neural_networks.html#ga2324b730b593482fda8f8f3a129ba06d">ANeuralNetworksModel_finish</a> has been called will return an error.</p>
<p>See <a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> for information on multithreaded usage.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">model</td><td>The model to be modified. </td></tr>
    <tr><td class="paramname">index</td><td>The index of the model operand we're setting. </td></tr>
    <tr><td class="paramname">buffer</td><td>A pointer to the data to use. </td></tr>
    <tr><td class="paramname">length</td><td>The size in bytes of the data value.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>ANEURALNETWORKS_NO_ERROR if successful. </dd></dl>

</div>
</div>
<a class="anchor" id="gadd7a4261e062051516fd49c7217c20b8"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int ANeuralNetworksModel_setOperandValueFromMemory </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> *&#160;</td>
          <td class="paramname"><em>model</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int32_t&#160;</td>
          <td class="paramname"><em>index</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="group___neural_networks.html#ga9a6b7719f0613ba9e2c93cffd97ebfc0">ANeuralNetworksMemory</a> *&#160;</td>
          <td class="paramname"><em>memory</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t&#160;</td>
          <td class="paramname"><em>length</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Sets an operand to a value stored in a memory object. </p>
<p>The content of the memory is not copied. A reference to that memory is stored inside the model. The application is responsible for not changing the content of the memory region until all executions using this model have completed. As the data may be copied during processing, modifying the data after this call yields undefined results.</p>
<p>To indicate that an optional operand should be considered missing, use <a class="el" href="group___neural_networks.html#gab95e96267e0f955086b87a743dad44ca">ANeuralNetworksModel_setOperandValue</a> instead, passing nullptr for buffer.</p>
<p>Attempting to modify a model once <a class="el" href="group___neural_networks.html#ga2324b730b593482fda8f8f3a129ba06d">ANeuralNetworksModel_finish</a> has been called will return an error.</p>
<p>See <a class="el" href="group___neural_networks.html#ga4ce6f20a94d3a2de47fa5a810feeb9a4">ANeuralNetworksModel</a> for information on multithreaded usage.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">model</td><td>The model to be modified. </td></tr>
    <tr><td class="paramname">index</td><td>The index of the model operand we're setting. </td></tr>
    <tr><td class="paramname">buffer</td><td>A pointer to the data to use. </td></tr>
    <tr><td class="paramname">memory</td><td>The memory containing the data. </td></tr>
    <tr><td class="paramname">offset</td><td>This specifies the location of the data within the memory. The offset is in bytes from the start of memory. </td></tr>
    <tr><td class="paramname">length</td><td>The size in bytes of the data value.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>ANEURALNETWORKS_NO_ERROR if successful. </dd></dl>

</div>
</div>
<h2 class="groupheader">Variable Documentation</h2>
<a class="anchor" id="ga8e9b0f8229777661e6005b9d1847f026"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">uint32_t ANeuralNetworksOperandType::dimensionCount</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The number of dimensions. </p>
<p>It should be 0 for scalars. </p>

<p>Definition at line <a class="el" href="_neural_networks_8h_source.html#l01379">1379</a> of file <a class="el" href="_neural_networks_8h_source.html">NeuralNetworks.h</a>.</p>

</div>
</div>
<a class="anchor" id="ga6d70bf7a7ea5d2e61e674cf7b3393548"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">const uint32_t* ANeuralNetworksOperandType::dimensions</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The dimensions of the tensor. </p>
<p>It should be nullptr for scalars. </p>

<p>Definition at line <a class="el" href="_neural_networks_8h_source.html#l01381">1381</a> of file <a class="el" href="_neural_networks_8h_source.html">NeuralNetworks.h</a>.</p>

</div>
</div>
<a class="anchor" id="gaee95637670d7b7179b28a9d5a22f621a"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">float ANeuralNetworksOperandType::scale</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>These two fields are only used for quantized tensors. </p>
<p>They should be zero for scalars and non-fixed point tensors. The dequantized value of each entry is (value - zeroPoint) * scale. </p>

<p>Definition at line <a class="el" href="_neural_networks_8h_source.html#l01386">1386</a> of file <a class="el" href="_neural_networks_8h_source.html">NeuralNetworks.h</a>.</p>

</div>
</div>
<a class="anchor" id="gaebe0bf8514de064d1d68e8857a3dccfd"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int32_t ANeuralNetworksOperandType::type</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>The data type, e.g ANEURALNETWORKS_INT8. </p>

<p>Definition at line <a class="el" href="_neural_networks_8h_source.html#l01377">1377</a> of file <a class="el" href="_neural_networks_8h_source.html">NeuralNetworks.h</a>.</p>

</div>
</div>
</div><!-- contents -->
<!-- HTML footer for doxygen 1.8.14-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Thu Apr 19 2018 13:03:57 for Caffe2 - C++ API by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
<div class="footerContainer">
  <div id="footer_wrap" class="wrapper footerWrapper">
    <div class="footerBlocks">
      <div id="fb_oss" class="footerSection fbOpenSourceFooter">
          <svg class="facebookOSSLogoSvg" viewBox="0 0 1133.9 1133.9" x="0px" y="0px" height=50 width=50>
            <g>
              <path class="logoRing outerRing" d="M 498.3 3.7 c 153.6 88.9 307.3 177.7 461.1 266.2 c 7.6 4.4 10.3 9.1 10.3 17.8 c -0.3 179.1 -0.2 358.3 0 537.4 c 0 8.1 -2.4 12.8 -9.7 17.1 c -154.5 88.9 -308.8 178.1 -462.9 267.5 c -9 5.2 -15.5 5.3 -24.6 0.1 c -153.9 -89.2 -307.9 -178 -462.1 -266.8 C 3 838.8 0 833.9 0 825.1 c 0.3 -179.1 0.2 -358.3 0 -537.4 c 0 -8.6 2.6 -13.6 10.2 -18 C 164.4 180.9 318.4 92 472.4 3 C 477 -1.5 494.3 -0.7 498.3 3.7 Z M 48.8 555.3 c 0 79.9 0.2 159.9 -0.2 239.8 c -0.1 10 3 15.6 11.7 20.6 c 137.2 78.8 274.2 157.8 411 237.3 c 9.9 5.7 17 5.7 26.8 0.1 c 137.5 -79.8 275.2 -159.2 412.9 -238.5 c 7.4 -4.3 10.5 -8.9 10.5 -17.8 c -0.3 -160.2 -0.3 -320.5 0 -480.7 c 0 -8.8 -2.8 -13.6 -10.3 -18 C 772.1 218 633.1 137.8 494.2 57.4 c -6.5 -3.8 -11.5 -4.5 -18.5 -0.5 C 336.8 137.4 197.9 217.7 58.8 297.7 c -7.7 4.4 -10.2 9.2 -10.2 17.9 C 48.9 395.5 48.8 475.4 48.8 555.3 Z" />
              <path class="logoRing middleRing" d="M 184.4 555.9 c 0 -33.3 -1 -66.7 0.3 -100 c 1.9 -48 24.1 -86 64.7 -110.9 c 54.8 -33.6 110.7 -65.5 167 -96.6 c 45.7 -25.2 92.9 -24.7 138.6 1 c 54.4 30.6 108.7 61.5 162.2 93.7 c 44 26.5 67.3 66.8 68 118.4 c 0.9 63.2 0.9 126.5 0 189.7 c -0.7 50.6 -23.4 90.7 -66.6 116.9 c -55 33.4 -110.8 65.4 -167.1 96.5 c -43.4 24 -89 24.2 -132.3 0.5 c -57.5 -31.3 -114.2 -64 -170 -98.3 c -41 -25.1 -62.9 -63.7 -64.5 -112.2 C 183.5 621.9 184.3 588.9 184.4 555.9 Z M 232.9 556.3 c 0 29.5 0.5 59.1 -0.1 88.6 c -0.8 39.2 16.9 67.1 50.2 86.2 c 51.2 29.4 102.2 59.2 153.4 88.4 c 31.4 17.9 63.6 18.3 95 0.6 c 53.7 -30.3 107.1 -61.2 160.3 -92.5 c 29.7 -17.5 45 -44.5 45.3 -78.8 c 0.6 -61.7 0.5 -123.5 0 -185.2 c -0.3 -34.4 -15.3 -61.5 -44.9 -79 C 637.7 352.6 583 320.8 527.9 290 c -27.5 -15.4 -57.2 -16.1 -84.7 -0.7 c -56.9 31.6 -113.4 64 -169.1 97.6 c -26.4 15.9 -40.7 41.3 -41.1 72.9 C 232.6 491.9 232.9 524.1 232.9 556.3 Z" />
              <path class="logoRing innerRing" d="M 484.9 424.4 c 69.8 -2.8 133.2 57.8 132.6 132 C 617 630 558.5 688.7 484.9 689.1 c -75.1 0.4 -132.6 -63.6 -132.7 -132.7 C 352.1 485 413.4 421.5 484.9 424.4 Z M 401.3 556.7 c -3.4 37.2 30.5 83.6 83 84.1 c 46.6 0.4 84.8 -37.6 84.9 -84 c 0.1 -46.6 -37.2 -84.4 -84.2 -84.6 C 432.2 472.1 397.9 518.3 401.3 556.7 Z" />
            </g>
          </svg>
        <h2>Facebook Open Source</h2>
      </div>
      <div class="footerSection">
        <a class="footerLink" href="https://code.facebook.com/projects/" target="_blank">Open Source Projects</a>
        <a class="footerLink" href="https://github.com/facebook/" target="_blank">GitHub</a>
        <a class="footerLink" href="https://twitter.com/fbOpenSource" target="_blank">Twitter</a>
      </div>
      <div class="footerSection rightAlign">
        <a class="footerLink" href="https://github.com/pytorch/pytorch" target="_blank">Contribute to this project on GitHub</a>
      </div>
    </div>
  </div>
</div>
<script type="text/javascript" src="/js/jekyll-link-anchors.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', '{{ site.gacode }}', 'auto');
  ga('send', 'pageview');
</script>
</body>
</html>
